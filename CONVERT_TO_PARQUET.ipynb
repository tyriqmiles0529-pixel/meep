{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert NBA Dataset to Parquet\n",
    "\n",
    "This notebook converts the gzipped CSV to Parquet format for 10x faster loading.\n",
    "\n",
    "## Steps:\n",
    "1. Add \"meeper\" dataset (Add Data -> search \"meeper\")\n",
    "2. Run the cell below (takes ~10 min)\n",
    "3. Download parquet from Output tab\n",
    "4. Upload as new Kaggle dataset\n",
    "\n",
    "**No GPU needed** - just CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_path = '/kaggle/input/meeper/aggregated_nba_data.csv/aggregated_nba_data.csv.gzip'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONVERTING CSV TO PARQUET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check file exists\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"ERROR: Dataset not found!\")\n",
    "    print(\"Add 'meeper' dataset: Add Data -> search 'meeper' -> Add\")\n",
    "else:\n",
    "    csv_size = os.path.getsize(csv_path) / 1024**2\n",
    "    print(f\"Input: {csv_path}\")\n",
    "    print(f\"Size: {csv_size:.1f} MB (compressed)\")\n",
    "    \n",
    "    print(\"\\nStep 1/3: Loading CSV (this takes 5-10 minutes)...\")\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    print(f\"✅ Loaded {len(df):,} rows, {len(df.columns)} columns\")\n",
    "    \n",
    "    # Show memory usage\n",
    "    mem_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"   Memory usage: {mem_mb:.1f} MB\")\n",
    "    \n",
    "    # Show year range\n",
    "    if 'season_end_year' in df.columns:\n",
    "        print(f\"   Year range: {df['season_end_year'].min()}-{df['season_end_year'].max()}\")\n",
    "    \n",
    "    print(\"\\nStep 2/3: Saving as Parquet (snappy compression)...\")\n",
    "    parquet_path = 'aggregated_nba_data.parquet'\n",
    "    df.to_parquet(parquet_path, compression='snappy', index=False)\n",
    "    \n",
    "    parquet_size = os.path.getsize(parquet_path) / 1024**2\n",
    "    print(f\"✅ Saved: {parquet_path}\")\n",
    "    print(f\"   Size: {parquet_size:.1f} MB\")\n",
    "    print(f\"   Compression ratio: {csv_size/parquet_size:.1f}x\")\n",
    "    \n",
    "    print(\"\\nStep 3/3: Download and upload\")\n",
    "    print(\"   1. Look at right sidebar -> Output tab\")\n",
    "    print(\"   2. Find 'aggregated_nba_data.parquet'\")\n",
    "    print(\"   3. Click download icon\")\n",
    "    print(\"   4. Go to kaggle.com/datasets/new\")\n",
    "    print(\"   5. Upload the parquet file\")\n",
    "    print(\"   6. Name it 'nba-aggregated-parquet'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DONE! Parquet file ready for download\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
