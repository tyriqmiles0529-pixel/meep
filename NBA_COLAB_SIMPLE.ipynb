{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ NBA Predictor - Cloud Training (FIXED)\n",
    "\n",
    "## Steps:\n",
    "1. Upload your files\n",
    "2. Run training\n",
    "3. Download models\n",
    "\n",
    "**Time:** 20-30 minutes with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 1: Upload Your Data Files\n# ============================================================\n# Upload 2 files:\n# 1. PlayerStatistics.csv.zip (39.5 MB - compressed)\n# 2. priors_data.zip (Basketball Reference stats)\n\nfrom google.colab import files\nimport os\n\nprint(\"üì§ Upload PlayerStatistics.csv.zip AND priors_data.zip:\")\nuploaded = files.upload()\n\n# Extract both files\nprint(\"\\nüì¶ Extracting files...\")\nif os.path.exists('PlayerStatistics.csv.zip'):\n    !unzip -q PlayerStatistics.csv.zip\n    !rm PlayerStatistics.csv.zip\n    print(\"‚úÖ PlayerStatistics.csv extracted\")\n\nif os.path.exists('priors_data.zip'):\n    !unzip -q priors_data.zip\n    print(\"‚úÖ priors_data extracted\")\n\n# VERIFY FIX IMMEDIATELY (test historical data, not just recent)\nprint(\"\\nüîç Verifying player data fix...\")\nimport pandas as pd\nimport numpy as np\n\n# Load sample from MIDDLE of file (where historical data is)\nprint(\"   Loading sample from historical range (rows 500,000-510,000)...\")\nps_sample = pd.read_csv('PlayerStatistics.csv', skiprows=500000, nrows=10000, low_memory=False)\nprint(f\"   Loaded sample: {len(ps_sample):,} rows\")\n\n# Get header separately since we skipped rows\nheader = pd.read_csv('PlayerStatistics.csv', nrows=0).columns.tolist()\nps_sample.columns = header\n\ndate_col = [c for c in ps_sample.columns if 'date' in c.lower()][0]\nprint(f\"   Date column: '{date_col}'\")\n\n# Parse dates\nps_sample[date_col] = pd.to_datetime(ps_sample[date_col], errors='coerce')\nprint(f\"   Non-null dates: {ps_sample[date_col].notna().sum()} / {len(ps_sample)}\")\n\nif ps_sample[date_col].notna().sum() > 0:\n    date_range = f\"{ps_sample[date_col].min()} to {ps_sample[date_col].max()}\"\n    print(f\"   Date range in sample: {date_range}\")\n\n# Use exact logic from train_auto.py\ndef _season_from_date(dt):\n    if pd.api.types.is_datetime64_any_dtype(dt):\n        d = dt\n    else:\n        d = pd.to_datetime(dt, errors=\"coerce\", utc=False)\n    y = d.dt.year\n    m = d.dt.month\n    return np.where(m >= 8, y + 1, y)\n\n# Test filtering for window 2002-2006\nwindow_seasons = [2002, 2003, 2004, 2005, 2006]\nstart_year = 2002\nend_year = 2006\npadded_seasons = set(window_seasons) | {start_year-1, end_year+1}\n\nprint(f\"\\n   Testing window: {window_seasons}\")\n\n# Apply fix\ntemp_seasons = pd.Series(_season_from_date(ps_sample[date_col]))\nps_sample['_temp_season'] = temp_seasons.fillna(-1).astype(int)\n\n# Filter\nfiltered = ps_sample[ps_sample['_temp_season'].isin(padded_seasons)]\n\nprint(f\"   üìä RESULT: {len(ps_sample):,} rows ‚Üí {len(filtered):,} rows\")\n\nif len(filtered) == 0:\n    print(\"\\n   ‚ö†Ô∏è WARNING: No data in historical range!\")\n    seasons_found = sorted([s for s in ps_sample['_temp_season'].unique() if s != -1])\n    print(f\"   Available seasons in sample: {seasons_found[:20]}\")\n    print(\"\\n   Trying rows 100k-110k instead...\")\n    ps_sample2 = pd.read_csv('PlayerStatistics.csv', skiprows=100000, nrows=10000, low_memory=False)\n    ps_sample2.columns = header\n    ps_sample2[date_col] = pd.to_datetime(ps_sample2[date_col], errors='coerce')\n    temp_seasons2 = pd.Series(_season_from_date(ps_sample2[date_col]))\n    ps_sample2['_temp_season'] = temp_seasons2.fillna(-1).astype(int)\n    filtered2 = ps_sample2[ps_sample2['_temp_season'].isin(padded_seasons)]\n    print(f\"   Result: {len(filtered2):,} rows\")\n    if len(filtered2) > 0:\n        print(\"   ‚úÖ Found historical data!\")\n    else:\n        print(\"   ‚ùå Still no historical data - file may be corrupted\")\nelse:\n    print(f\"   ‚úÖ Player data verified! Filtering works correctly.\")\n\nprint(\"\\n‚úÖ All files uploaded and ready!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2: Setup & Train\n# ============================================================\n\nprint(\"üì¶ Installing packages...\")\n!pip install -q nba-api kagglehub pytorch-tabnet lightgbm scikit-learn pandas numpy tqdm\n\nprint(\"\\nüì• Downloading code...\")\nimport os\nos.chdir('/content')\n!git clone https://github.com/tyriqmiles0529-pixel/meep.git\nos.chdir('meep')\n\nprint(\"\\nüìç Code version:\")\n!git log -1 --oneline\n\n# Check GPU\nimport torch\nprint(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Not available'}\")\n\nprint(\"\\nüöÄ Starting training (20-30 min)...\\n\")\n!python3 train_auto.py \\\n    --priors-dataset /content/priors_data \\\n    --player-csv /content/PlayerStatistics.csv \\\n    --verbose \\\n    --fresh \\\n    --neural-device gpu \\\n    --neural-epochs 50\n\nprint(\"\\n‚úÖ TRAINING COMPLETE!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Download Models\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì¶ Packaging models...\")\n",
    "!zip -q -r nba_models_trained.zip models/ model_cache/\n",
    "\n",
    "print(\"üíæ Downloading...\")\n",
    "files.download('nba_models_trained.zip')\n",
    "\n",
    "print(\"\\n‚úÖ Done! Extract nba_models_trained.zip to your local nba_predictor folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Troubleshooting\n",
    "\n",
    "### \"Loaded 0 player-games for window\"\n",
    "- Make sure you uploaded **PlayerStatistics.csv.zip** (not the uncompressed version)\n",
    "- Verify file is 39.5 MB compressed\n",
    "\n",
    "### \"No GPU available\"\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or L4)\n",
    "\n",
    "### \"Out of memory\"\n",
    "- Runtime ‚Üí Restart runtime\n",
    "- Re-run from Step 1\n",
    "\n",
    "---\n",
    "\n",
    "**Version:** 2.2 (Simplified, Fixed)\n",
    "\n",
    "**What's included:**\n",
    "- Game models (moneyline, spread)\n",
    "- Player models (points, rebounds, assists, 3PM, minutes)\n",
    "- Ensemble (Ridge + Elo + Four Factors + LightGBM)\n",
    "- Neural hybrid (TabNet + LightGBM)\n",
    "- 20+ years of historical data\n",
    "- Basketball Reference priors (~68 features)\n",
    "\n",
    "**Expected output:**\n",
    "```\n",
    "Training window 1/5: 2002-2006\n",
    "  ‚Ä¢ Loaded 245,892 player-games for window  ‚úÖ\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}