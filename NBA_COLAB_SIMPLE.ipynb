{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ NBA Predictor - Cloud Training (FIXED)\n",
    "\n",
    "## Steps:\n",
    "1. Upload your files\n",
    "2. Run training\n",
    "3. Download models\n",
    "\n",
    "**Time:** 20-30 minutes with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 1: Upload Your Data Files\n# ============================================================\n# Upload 2 files:\n# 1. PlayerStatistics.csv.zip (39.5 MB - compressed)\n# 2. priors_data.zip (Basketball Reference stats)\n\nfrom google.colab import files\nimport os\n\nprint(\"üì§ Upload PlayerStatistics.csv.zip AND priors_data.zip:\")\nuploaded = files.upload()\n\n# Extract both files\nprint(\"\\nüì¶ Extracting files...\")\nif os.path.exists('PlayerStatistics.csv.zip'):\n    !unzip -q PlayerStatistics.csv.zip\n    !rm PlayerStatistics.csv.zip\n    print(\"‚úÖ PlayerStatistics.csv extracted\")\n\nif os.path.exists('priors_data.zip'):\n    !unzip -q priors_data.zip\n    print(\"‚úÖ priors_data extracted\")\n\n# VERIFY FIX IMMEDIATELY (while data is fresh in memory)\nprint(\"\\nüîç Verifying player data fix...\")\nimport pandas as pd\nimport numpy as np\n\n# Test the fix on a sample\nps_sample = pd.read_csv('PlayerStatistics.csv', nrows=10000, low_memory=False)\nprint(f\"   Loaded sample: {len(ps_sample):,} rows\")\nprint(f\"   Columns: {list(ps_sample.columns)[:10]}...\")\n\ndate_col = [c for c in ps_sample.columns if 'date' in c.lower()][0]\nprint(f\"   Date column: '{date_col}'\")\nprint(f\"   Sample dates (raw): {ps_sample[date_col].head(3).tolist()}\")\n\nps_sample[date_col] = pd.to_datetime(ps_sample[date_col], errors='coerce')\nprint(f\"   Non-null dates: {ps_sample[date_col].notna().sum()} / {len(ps_sample)}\")\n\n# Use exact logic from train_auto.py\ndef _season_from_date(dt):\n    if pd.api.types.is_datetime64_any_dtype(dt):\n        d = dt\n    else:\n        d = pd.to_datetime(dt, errors=\"coerce\", utc=False)\n    y = d.dt.year\n    m = d.dt.month\n    return np.where(m >= 8, y + 1, y)\n\n# Test filtering for window 2002-2006\nwindow_seasons = [2002, 2003, 2004, 2005, 2006]\nstart_year = 2002\nend_year = 2006\npadded_seasons = set(window_seasons) | {start_year-1, end_year+1}\n\nprint(f\"\\n   Testing window: {window_seasons}\")\nprint(f\"   Padded seasons: {sorted(padded_seasons)}\")\n\n# Apply fix\ntemp_seasons = pd.Series(_season_from_date(ps_sample[date_col]))\nprint(f\"   Seasons dtype (before): {temp_seasons.dtype}\")\nprint(f\"   Sample seasons: {temp_seasons.dropna().head(10).tolist()}\")\n\nps_sample['_temp_season'] = temp_seasons.fillna(-1).astype(int)\nprint(f\"   Seasons dtype (after): {ps_sample['_temp_season'].dtype}\")\n\n# Filter\nfiltered = ps_sample[ps_sample['_temp_season'].isin(padded_seasons)]\n\nprint(f\"\\n   üìä RESULT: {len(ps_sample):,} rows ‚Üí {len(filtered):,} rows\")\n\nif len(filtered) == 0:\n    print(\"\\n   ‚ùå CRITICAL ERROR: Filtering returns 0 rows!\")\n    print(\"   Debugging info:\")\n    print(f\"     ‚Ä¢ Available seasons in sample: {sorted(ps_sample['_temp_season'].unique())[:20]}\")\n    print(f\"     ‚Ä¢ Looking for seasons: {sorted(padded_seasons)}\")\n    print(f\"     ‚Ä¢ Season overlap: {set(ps_sample['_temp_season'].unique()) & padded_seasons}\")\n    print(\"\\n   This PlayerStatistics.csv is INVALID or CORRUPTED!\")\nelse:\n    print(f\"   ‚úÖ Player data verified! Filtering works correctly.\")\n    season_dist = filtered['_temp_season'].value_counts().sort_index().to_dict()\n    print(f\"   Season distribution: {season_dist}\")\n\nprint(\"\\n‚úÖ All files uploaded and ready!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2: Setup & Train\n# ============================================================\n\nprint(\"üì¶ Installing packages...\")\n!pip install -q nba-api kagglehub pytorch-tabnet lightgbm scikit-learn pandas numpy tqdm\n\nprint(\"\\nüì• Downloading code...\")\nimport os\nos.chdir('/content')\n!git clone https://github.com/tyriqmiles0529-pixel/meep.git\nos.chdir('meep')\n\nprint(\"\\nüìç Code version:\")\n!git log -1 --oneline\n\n# Check GPU\nimport torch\nprint(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Not available'}\")\n\nprint(\"\\nüöÄ Starting training (20-30 min)...\\n\")\n!python3 train_auto.py \\\n    --priors-dataset /content/priors_data \\\n    --player-csv /content/PlayerStatistics.csv \\\n    --verbose \\\n    --fresh \\\n    --neural-device gpu \\\n    --neural-epochs 50\n\nprint(\"\\n‚úÖ TRAINING COMPLETE!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Download Models\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì¶ Packaging models...\")\n",
    "!zip -q -r nba_models_trained.zip models/ model_cache/\n",
    "\n",
    "print(\"üíæ Downloading...\")\n",
    "files.download('nba_models_trained.zip')\n",
    "\n",
    "print(\"\\n‚úÖ Done! Extract nba_models_trained.zip to your local nba_predictor folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì Troubleshooting\n",
    "\n",
    "### \"Loaded 0 player-games for window\"\n",
    "- Make sure you uploaded **PlayerStatistics.csv.zip** (not the uncompressed version)\n",
    "- Verify file is 39.5 MB compressed\n",
    "\n",
    "### \"No GPU available\"\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or L4)\n",
    "\n",
    "### \"Out of memory\"\n",
    "- Runtime ‚Üí Restart runtime\n",
    "- Re-run from Step 1\n",
    "\n",
    "---\n",
    "\n",
    "**Version:** 2.2 (Simplified, Fixed)\n",
    "\n",
    "**What's included:**\n",
    "- Game models (moneyline, spread)\n",
    "- Player models (points, rebounds, assists, 3PM, minutes)\n",
    "- Ensemble (Ridge + Elo + Four Factors + LightGBM)\n",
    "- Neural hybrid (TabNet + LightGBM)\n",
    "- 20+ years of historical data\n",
    "- Basketball Reference priors (~68 features)\n",
    "\n",
    "**Expected output:**\n",
    "```\n",
    "Training window 1/5: 2002-2006\n",
    "  ‚Ä¢ Loaded 245,892 player-games for window  ‚úÖ\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}