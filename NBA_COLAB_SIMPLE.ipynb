{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ€ NBA Predictor - Cloud Training (A100 Optimized)\n\n## Features:\n- âœ… Full historical data: **1974-2025** (50 years, ALL NBA eras)\n- âœ… **10-30x faster momentum features** (vectorized NumPy)\n- âœ… **Neural hybrid: TabNet + LightGBM for BOTH game and player models**\n- âœ… Basketball Reference priors: ~68 advanced stats\n- âœ… **Overfitting prevention** for game models (shallow architecture)\n\n## Quick Start:\n1. **Run the first cell** - It will prompt for file upload if needed\n2. Upload 2 files: PlayerStatistics.csv.zip (41 MB) + priors_data.zip (4.8 MB)\n3. Wait 23-30 minutes (A100) or 30-40 minutes (T4/L4)\n4. Download models\n\n**GPU Recommended:** A100 (fastest), L4, or T4\n\n## What's New (v3.2):\n- ğŸš€ **Momentum features 10-30x faster** (10-20 min â†’ 30-90 sec)\n- ğŸ§  **Neural hybrid ENABLED by default** for game models\n- âš¡ **100-200x faster adaptive temporal features** (5-10 min â†’ 2-5 sec)\n- ğŸ›¡ï¸ **Overfitting prevention** (shallow TabNet, strong regularization)\n- ğŸ¯ **Expected game accuracy: 63.5-64.5%** (vs 62.6% LightGBM-only)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SETUP & TRAIN (ALL-IN-ONE)\n# ============================================================\n\nprint(\"ğŸ“¦ Installing packages...\")\n!pip install -q nba-api kagglehub pytorch-tabnet lightgbm scikit-learn pandas numpy tqdm\n\nprint(\"\\nğŸ“¥ Downloading code...\")\nimport os\nimport shutil\nfrom google.colab import files\n\nos.chdir('/content')\n\n# Remove old code if exists\nif os.path.exists('meep'):\n    shutil.rmtree('meep')\n    print(\"ğŸ§¹ Cleaned up old code\")\n\n!git clone https://github.com/tyriqmiles0529-pixel/meep.git\nos.chdir('meep')\n\nprint(\"\\nğŸ“ Code version:\")\n!git log -1 --oneline\n\n# CHECK IF FILES ALREADY UPLOADED\nfiles_exist = os.path.exists('/content/PlayerStatistics.csv') and os.path.exists('/content/priors_data')\n\nif not files_exist:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ“¤ UPLOAD REQUIRED: Please upload your data files\")\n    print(\"=\"*70)\n    print(\"\\nYou need 2 files:\")\n    print(\"  1. PlayerStatistics.csv.zip (41 MB)\")\n    print(\"  2. priors_data.zip (4.8 MB)\")\n    print(\"\\nUploading...\")\n    \n    os.chdir('/content')\n    uploaded = files.upload()\n    \n    # Extract files\n    print(\"\\nğŸ“¦ Extracting files...\")\n    if os.path.exists('PlayerStatistics.csv.zip'):\n        !unzip -q PlayerStatistics.csv.zip\n        !rm PlayerStatistics.csv.zip\n        print(\"âœ… PlayerStatistics.csv extracted\")\n    \n    if os.path.exists('priors_data.zip'):\n        !unzip -q priors_data.zip\n        print(\"âœ… priors_data extracted\")\n    \n    os.chdir('/content/meep')\nelse:\n    print(\"\\nâœ“ Files already uploaded, skipping upload step\")\n\n# VERIFY FILES EXIST\nprint(\"\\nğŸ” Pre-flight check:\")\nif os.path.exists('/content/PlayerStatistics.csv'):\n    size_mb = os.path.getsize('/content/PlayerStatistics.csv') / 1024 / 1024\n    print(f\"   âœ… PlayerStatistics.csv ({size_mb:.1f} MB)\")\nelse:\n    raise FileNotFoundError(\"âŒ PlayerStatistics.csv not found after upload!\")\n\nif os.path.exists('/content/priors_data'):\n    csv_files = [f for f in os.listdir('/content/priors_data') if f.endswith('.csv')]\n    print(f\"   âœ… priors_data ({len(csv_files)} CSV files)\")\nelse:\n    raise FileNotFoundError(\"âŒ priors_data not found after upload!\")\n\n# Check GPU\nimport torch\ngpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Not available'\nprint(f\"\\nğŸ® GPU: {gpu_name}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸš€ STARTING TRAINING\")\nprint(\"=\"*70)\nprint(\"\\nğŸ“Š Dataset: 1974-2025 (50+ years, 7 NBA eras)\")\nprint(\"ğŸ§  Features: Temporal + Basketball Reference priors + Momentum\")\nprint(\"âš¡ Neural hybrid: TabNet + LightGBM on GPU (game + player models)\")\nprint(\"ğŸš€ Optimizations: 10-30x faster momentum features\")\n\nif 'A100' in gpu_name:\n    print(\"â±ï¸  Expected time: 23-30 minutes (A100 detected!)\")\nelse:\n    print(\"â±ï¸  Expected time: 30-40 minutes\")\n\nprint(\"\\nğŸ’¡ Neural hybrid ENABLED for both game and player models\")\nprint(\"   Expected: +1-2% game accuracy (62.6% â†’ 63.5-64.5%)\\n\")\n\n# NEURAL HYBRID MODE (game + player models with TabNet)\n!python3 train_auto.py \\\n    --game-neural \\\n    --priors-dataset /content/priors_data \\\n    --player-csv /content/PlayerStatistics.csv \\\n    --verbose \\\n    --fresh \\\n    --neural-device gpu \\\n    --neural-epochs 50 \\\n    --no-window-ensemble \\\n    --game-season-cutoff 1974 \\\n    --player-season-cutoff 1974\n\n# FALLBACK: LightGBM-only game models (uncomment if neural fails)\n# !python3 train_auto.py \\\n#     --priors-dataset /content/priors_data \\\n#     --player-csv /content/PlayerStatistics.csv \\\n#     --verbose \\\n#     --fresh \\\n#     --neural-device gpu \\\n#     --neural-epochs 50 \\\n#     --no-window-ensemble \\\n#     --game-season-cutoff 1974 \\\n#     --player-season-cutoff 1974\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… TRAINING COMPLETE!\")\nprint(\"=\"*70)\nprint(\"\\nNext: Run the Download Models cell to get your trained models\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note:** If upload fails or you need to re-upload files:\n",
    "1. Delete `/content/PlayerStatistics.csv` and `/content/priors_data`\n",
    "2. Re-run this cell - it will prompt for upload again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Download Models\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“¦ Packaging models...\")\n",
    "!zip -q -r nba_models_trained.zip models/ model_cache/\n",
    "\n",
    "print(\"ğŸ’¾ Downloading...\")\n",
    "files.download('nba_models_trained.zip')\n",
    "\n",
    "print(\"\\nâœ… Done! Extract nba_models_trained.zip to your local nba_predictor folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## â“ Troubleshooting\n\n### \"Loaded 0 player-games for window\"\n- Make sure you uploaded **PlayerStatistics.csv.zip** (39.5 MB compressed)\n- File must be the ZIPPED version (not uncompressed CSV)\n- Verify extraction completed successfully\n\n### \"No GPU available\"\n- Runtime â†’ Change runtime type â†’ GPU\n- Select A100 (fastest), L4, or T4\n- A100: 23-30 min | L4: 30 min | T4: 40 min\n\n### \"Out of memory\"\n- Runtime â†’ Restart runtime\n- Re-run all cells from Step 1\n- Consider reducing `--neural-epochs` to 30\n\n### \"Session timeout\"\n- Colab Free: 12-hour limit, may disconnect\n- Colab Pro: More stable for 30+ min training\n- Keep browser tab active during training\n\n---\n\n## ğŸ“Š Dataset Details\n\n**PlayerStatistics.csv** (Kaggle: eoinamoore/historical-nba-data-and-player-box-scores)\n- **Date Range:** November 26, 1946 â†’ November 4, 2025\n- **Total Records:** 1,632,909 player-game statistics\n- **Seasons:** 80 complete seasons (1947-2026)\n- **Unique Dates:** 34,108 game dates\n\n**Era Distribution:**\n- Pre-3pt (â‰¤1979): 17.8% | Early 3pt (1980-1983): 4.8%\n- Hand-check (1984-2003): 30.4% | Pace Slow (2004-2012): 18.3%\n- 3pt Revolution (2013-2016): 9.0% | Small Ball (2017-2020): 8.1%\n- Modern (2021+): 11.6%\n\n**priors_data.zip** (Basketball Reference statistical priors)\n- Team priors: Offensive/Defensive ratings, Pace, SRS\n- Player priors: Per 100 poss, Advanced stats, Shooting, Play-by-play\n- ~68 advanced features from historical seasons\n\n---\n\n## ğŸ¯ What's Included\n\n**Game Models (Neural Hybrid - NEW!):**\n- Moneyline classifier (P(home wins), isotonic calibration)\n- Spread regressor (expected margin, cover probabilities)\n- **TabNet + LightGBM ensemble** (40% neural + 60% tree)\n- **Expected accuracy: 63.5-64.5%** (beats Vegas vig at 52.4%)\n\n**Player Models (Neural Hybrid):**\n- Minutes, Points, Rebounds, Assists, 3-Pointers Made\n- Team context, opponent matchup, rolling trends\n- TabNet + LightGBM hybrid architecture\n- **RMSE < 3.5 for major props**\n\n**Features:**\n- **Momentum:** Short/medium/long-term trends (10-30x faster!)\n- **Temporal:** Era categories, time-weighted samples (100-200x faster!)\n- **Basketball Reference:** 68 advanced priors\n- **Four Factors:** eFG%, TOV%, ORB%, FTR\n\n**Performance Optimizations (v3.2):**\n- Vectorized NumPy momentum calculations (20-60x speedup)\n- Pandas EWM for adaptive temporal features (100-200x speedup)\n- Single-pass priors merging (60-150x speedup)\n- Eliminated all nested Python loops\n- **Total time saved: ~20-30 minutes per run**\n\n**Expected Training Output:**\n```\nğŸ§  Training on full historical dataset (1974-2025)\n  â€¢ Game models: 62,085 games (TabNet + LightGBM)\n  â€¢ Player models: 1.6M+ player-games (TabNet + LightGBM)\n  â€¢ Features: 229 (including 68 priors)\n  â€¢ Momentum features: ~90 seconds (was 10-20 min!)\n  â€¢ Adaptive temporal: ~3 seconds (was 5-10 min!)\n  â€¢ TabNet training: 15-20 min on A100\n```\n\n---\n\n## ğŸ§  Neural Hybrid Architecture (ENABLED)\n\n**Game Models:**\n- Shallow TabNet (3 steps) to prevent overfitting on 62k samples\n- Strong regularization (Î»_sparse=1e-3, weight decay=1e-4)\n- Ensemble: 40% TabNet + 60% LightGBM\n- **Why it works:** Captures non-linear feature interactions LightGBM misses\n\n**Player Models:**\n- Deep TabNet (5 steps) leverages 1.6M samples\n- Learns 32-dim embeddings from 229 features\n- LightGBM trained on [raw features + embeddings]\n- **Why it works:** Best of both worlds - DL pattern recognition + tree efficiency\n\n**Expected Benefits:**\n- Game models: +1-2% accuracy (62.6% â†’ 63.5-64.5%)\n- Player models: Better tail event predictions (big games, slumps)\n- Improved calibration for betting lines\n\n**Trade-offs:**\n- +5-8 min training time vs LightGBM-only\n- More complex models (harder to debug)\n- Requires GPU for practical training time\n\n**To disable game neural (use LightGBM only):**\nUncomment the fallback command in the training cell and comment out the neural hybrid command.\n\n---\n\n## ğŸ’¡ Optional: NBA API for Live Predictions\n\nAfter training, use `nba_api` for real-time game predictions:\n\n```python\n# Install: pip install nba-api\nfrom nba_api.stats.endpoints import ScoreboardV2\nfrom datetime import datetime\n\n# Get today's games\ntoday = datetime.now().strftime('%Y-%m-%d')\nscoreboard = ScoreboardV2(game_date=today)\ngames = scoreboard.get_data_frames()[0]\n\n# Use trained models to predict\n# (requires loading models and feature engineering pipeline)\n```\n\n**Note:** NBA API is for **live predictions only**, not training (too slow, rate-limited).\n\n---\n\n## ğŸ“ˆ Version History\n\n**v3.2 (2025-11-06)** - Neural Game Models Enabled\n- ğŸ§  **Neural hybrid ENABLED by default** for game models\n- âš¡ **100-200x faster adaptive temporal features** (pandas EWM)\n- ğŸ› **Fixed missing train_player_model_enhanced function**\n- ğŸ¯ Expected game accuracy: 63.5-64.5% (was 62.6%)\n- â±ï¸ Total training time: 23-30 min on A100\n\n**v3.1 (2025-11-06)** - Performance & Neural Enhancements\n- ğŸš€ 10-30x faster momentum features (vectorized NumPy)\n- ğŸ§  Optional neural hybrid for game models (--game-neural)\n- ğŸ›¡ï¸ Overfitting prevention (shallow TabNet, strong regularization)\n- ğŸ¯ A100 GPU support (18-25 min training)\n\n**v3.0** - Temporal Features, Full Historical Coverage\n- 1974-2025 dataset (50 years)\n- Era-aware training\n- Basketball Reference priors integration\n\n**Expected Accuracy:**\n- **Game models: 63.5-64.5%** (neural hybrid, ENABLED)\n- **Player models: RMSE < 3.5** for points/rebounds/assists\n- **Beating Vegas:** 52.4% needed to beat vig, we target 63%+"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}