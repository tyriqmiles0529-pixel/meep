{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üèÄ NBA Predictor - Neural Hybrid Training (Game + Player Models)\n\n## Features:\n- ‚úÖ **FULL NBA HISTORY**: 1947-2026 (80 seasons, 1.6M player-games)\n- ‚úÖ **Neural hybrid: TabNet + LightGBM** with 24-dim embeddings\n- ‚úÖ Basketball Reference priors: ~68 advanced stats (already merged!)\n- ‚úÖ **Game Models**: Moneyline + Spread predictions\n- ‚úÖ **Player Models**: Minutes, Points, Rebounds, Assists, Threes\n- ‚úÖ **Phase 1-7 features**: Built automatically during training\n\n## Quick Start:\n1. **Add \"meeper\" dataset** in Kaggle (Add Data ‚Üí search \"meeper\")\n2. **Enable GPU** (P100 or T4 x2)\n3. **Run Cell 1** (setup - 2 min)\n4. **Run Cell 2** (training - 7-8 hours)\n5. **Close browser** - Kaggle keeps running!\n6. **Come back later** and download models\n\n**GPU Required:** P100 (best) or T4 x2\n\n## What You Get:\n- **Game Models** (2): Moneyline classifier + Spread regressor\n- **Player Models** (5): Minutes, Points, Rebounds, Assists, Threes\n- **All with 24-dim embeddings** from TabNet + LightGBM\n- **Uncertainty quantification** via sigma models\n\n## Training Time:\n- **P100**: ~7 hours\n- **T4**: ~8 hours\n- Feature building: 90 min\n- Game models: 1 hour  \n- Player models: 5 hours\n\n## Expected Performance:\n- **Game accuracy**: 63.5-64.5% (beats Vegas 52.4% vig)\n- **Points MAE**: ~2.0-2.1 (22% better than baseline 2.65)\n- **Embeddings**: 24-dimensional, 15-40% feature importance"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SETUP (Kaggle Version)\n# ============================================================\n\nprint(\"üì¶ Installing packages...")\n!pip install -q pytorch-tabnet lightgbm scikit-learn pandas numpy tqdm\n\nprint(\"\nüì• Downloading training code from GitHub...")\nimport os\n\n# Navigate to Kaggle working directory\nos.chdir('/kaggle/working')\n\n# Clone your repository\n!git clone https://github.com/tyriqmiles0529-pixel/meep.git\nos.chdir('meep')\n\nprint(\"\nüìç Code version:")\n!git log -1 --oneline\n\n# Check GPU\nimport torch\ngpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Not available'\nprint(f"\nüéÆ GPU: {gpu_name}")\n\n# Verify dataset exists (added via \"Add Data\" in Kaggle UI)\ndataset_path = '/kaggle/input/meeper/aggregated_nba_data.csv/aggregated_nba_data.csv.gzip'\nif os.path.exists(dataset_path):\n    size_mb = os.path.getsize(dataset_path) / 1024 / 1024\n    print(f"\n‚úÖ Dataset found: {size_mb:.1f} MB")\n    print(f"   Path: {dataset_path}")\n    print(f"   Full NBA history: 1947-2026 (80 seasons, 1.6M player-games)")\n    print(f"   Training will use: ALL DATA (no cutoff)")\nelse:\n    print(\"\n‚ùå Dataset not found!")\n    print(\"   Make sure you added 'meeper' dataset to this notebook\")\n    print(\"   Click 'Add Data' ‚Üí search 'meeper' ‚Üí Add\")\n\nprint(\"\n‚úÖ Setup complete!")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ============================================================\n# TRAIN NEURAL HYBRID MODELS - GAME + PLAYER\n# ============================================================"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Make sure we're in the code directory\nos.chdir('/kaggle/working/meep')\n\nprint(\"="*70)\nprint(\"üöÄ NBA NEURAL HYBRID TRAINING - GAME + PLAYER MODELS\")\nprint(\"="*70)\n\nprint(\"\nüìä Dataset Info:")\nprint(\"   Source: /kaggle/input/meeper/aggregated_nba_data.csv/aggregated_nba_data.csv.gzip\")\nprint(\"   Full range: 1947-2026 (80 seasons, 1.6M player-games)\")\nprint(\"   Training on: ALL DATA (no cutoff)\")\nprint(\"   Contains: Raw stats + Basketball Reference priors (108 cols)\")\nprint(\"\n‚öôÔ∏è  What will happen:")\nprint(\"   1. Load aggregated data (30 sec)\")\nprint(\"   2. Build Phase 1-6 features (90 min)\")\nprint(\"   3. Train game models: Moneyline + Spread (1 hour)\")\nprint(\"   4. Train 5 player props with neural hybrid (5 hours)\")\nprint(\"\nüß† Architecture:")\nprint(\"   Game Models: Ensemble (TabNet + LightGBM)\")\nprint(\"   Player Models: TabNet (24-dim embeddings) + LightGBM\")\nprint(\"   Uncertainty: Sigma models for prediction intervals\")\n\nimport torch\ngpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n\nif 'P100' in gpu_name:\n    print(\"\n‚è±Ô∏è  Expected time: ~7-8 hours total (P100)\")\nelif 'T4' in gpu_name:\n    print(\"\n‚è±Ô∏è  Expected time: ~8-9 hours total (T4)\")\nelse:\n    print(\"\n‚è±Ô∏è  Expected time: ~7-9 hours\")\n\nprint(\"\nüí° Models to train:")\nprint(\"   Game: Moneyline (win probability), Spread (margin)\")\nprint(\"   Player: Minutes, Points, Rebounds, Assists, Threes\")\nprint(\"   Expected: Points MAE ~2.0-2.1 (with full 1.6M game history)\")\nprint(\"\n" + "="*70)\nprint(\"STARTING TRAINING...")\nprint("="*70 + "\n")\n\n# Run training - FULL DATASET, GAME + PLAYER MODELS\n!python train_auto.py \\\n    --dataset /kaggle/input/meeper/aggregated_nba_data.csv/aggregated_nba_data.csv.gzip \\\n    --priors-dataset /kaggle/input/meeper/priors_data.zip \\\n    --game-neural \\\n    --batch-size 16384 \\\n    --verbose"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# VALIDATE 24-DIM EMBEDDINGS\n# ============================================================\n\nimport os\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# Navigate to code directory\nos.chdir('/kaggle/working/meep')\n\nprint(\"üîç Validating TabNet embeddings...\\n\")\n\nmodels_dir = Path('./models')\n\n# Check if models directory exists\nif not models_dir.exists():\n    print(\"‚ùå Models directory not found!\")\n    print(\"   Expected: /kaggle/working/meep/models/\")\n    print(\"   Run training cell first\")\nelse:\n    # Find points model\n    model_files = list(models_dir.glob('*points*.pkl'))\n    \n    if not model_files:\n        print(\"‚ùå No points model found!\")\n        print(f\"   Searching in: {models_dir.absolute()}\")\n        print(f\"   Files found: {list(models_dir.glob('*.pkl'))}\")\n    else:\n        model_path = model_files[0]\n        print(f\"üì¶ Loading model: {model_path.name}\")\n        \n        with open(model_path, 'rb') as f:\n            model = pickle.load(f)\n        \n        print(f\"   Model type: {type(model).__name__}\")\n        \n        # Check if it's a NeuralHybridPredictor\n        if hasattr(model, 'tabnet'):\n            print(f\"   ‚úÖ Neural hybrid detected\")\n            print(f\"   TabNet: {type(model.tabnet).__name__}\")\n            print(f\"   LightGBM: {type(model.lgbm).__name__}\")\n            \n            # Test embedding extraction\n            print(\"\\nüß™ Testing embedding extraction...")\n            \n            # Create dummy data (match actual feature count)\n            n_features = 150  # Adjust if needed\n            dummy_features = pd.DataFrame(\n                np.random.randn(10, n_features),\n                columns=[f'feature_{i}' for i in range(n_features)]\n            )\n            \n            # Get embeddings\n            try:\n                if hasattr(model, '_get_embeddings'):\n                    embeddings = model._get_embeddings(dummy_features)\n                    print(f\"   ‚úÖ Embeddings extracted successfully!\")\n                    print(f\"   Shape: {embeddings.shape}\")\n                    print(f\"   Expected shape: (10, 24)\")\n                    assert embeddings.shape == (10, 24)\n                else:\n                    print(\"   ‚ùå _get_embeddings method not found!\")\n            except Exception as e:\n                print(f\"   ‚ùå Embedding extraction failed: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ============================================================\n# TRAINING RESULTS SUMMARY\n# ============================================================"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\nos.chdir('/kaggle/working/meep')\n\nmodels_dir = Path('./models')\n\nprint(\"="*70)\nprint(\"üìä TRAINING RESULTS\")\nprint(\"="*70)\n\nif not models_dir.exists():\n    print(\"\n‚ùå No models directory found!\")\nelse:\n    model_files = list(models_dir.glob('*.pkl'))\n    \n    if not model_files:\n        print(\"\n‚ùå No models found!\")\n        print(f\"   Directory: {models_dir.absolute()}\")\n    else:\n        print(f\"\n‚úÖ Found {len(model_files)} trained models:\\n\")\n        \n        for model_path in sorted(model_files):\n            print(f\"   üì¶ {model_path.name}\")\n            size_mb = model_path.stat().st_size / 1024 / 1024\n            print(f\"      Size: {size_mb:.1f} MB\")\n            \n            # Try to load and check type\n            try:\n                import pickle\n                with open(model_path, 'rb') as f:\n                    model = pickle.load(f)\n                \n                if hasattr(model, 'tabnet'):\n                    print(f\"      Type: Neural Hybrid ‚úÖ\")\n                else:\n                    print(f\"      Type: LightGBM only\")\n                \n                if hasattr(model, 'sigma_model') and model.sigma_model:\n                    print(f\"      Uncertainty: Yes ‚úÖ\")\n                \n                print()\n            except Exception as e:\n                print(f\"      Error loading: {e}\\n\")\n\nprint(\"="*70)\nprint(\"\nModels location: /kaggle/working/meep/models/\")\nprint(\"\nNext: Package and download models")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# PACKAGE MODELS FOR DOWNLOAD\n# ============================================================\n\nimport os\n\nos.chdir('/kaggle/working')\n\nprint(\"üì¶ Packaging models...")\n\n# Check if models exist\nif not os.path.exists('meep/models'):\n    print(\"\n‚ùå No models directory found!\")\n    print(\"   Run training first\")\nelse:\n    # Create zip file\n    !zip -r nba_models_trained.zip meep/models/ meep/model_cache/ 2>/dev/null\n    \n    # Check if zip was created\n    if os.path.exists('nba_models_trained.zip'):\n        size_mb = os.path.getsize('nba_models_trained.zip') / 1024 / 1024\n        print(f"\n‚úÖ Package created: nba_models_trained.zip ({size_mb:.1f} MB)")\n        print(\"\nüì• To download:")\n        print(\"   1. Look at the right sidebar\")\n        print(\"   2. Click 'Output' tab\")\n        print(\"   3. Find 'nba_models_trained.zip'\")\n        print(\"   4. Click the download icon (‚Üì)\")\n        print(\"\nOr use this command to download via Kaggle API:")\n        print(\"   (This requires Kaggle notebook to be public)\")\n    else:\n        print(\"\n‚ùå Failed to create zip file\")\n        print(\"   Check if models exist in meep/models/")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üìã What You Get After Training\n\n### Game Models (2 files):\n- `moneyline_ensemble_1947_2026.pkl` - Win probability predictions\n- `spread_ensemble_1947_2026.pkl` - Margin predictions\n- Both with TabNet + LightGBM ensemble architecture\n- Expected accuracy: 63.5-64.5%\n\n### Player Models (5 files):\n- `minutes_hybrid_1947_2026.pkl`\n- `points_hybrid_1947_2026.pkl`\n- `rebounds_hybrid_1947_2026.pkl`\n- `assists_hybrid_1947_2026.pkl`\n- `threes_hybrid_1947_2026.pkl`\n- All with 24-dimensional TabNet embeddings + LightGBM\n- Points MAE: ~2.0-2.1 (22% improvement over baseline)\n\n### Features Included:\n- **Raw stats**: 40 box score features from 1947-2026\n- **Basketball Reference priors**: 68 advanced stats (already merged!)\n- **Phase 1-6 features**: 150+ engineered features (built during training)\n- **Total**: ~235 features per prediction\n\n---\n\n## ‚è±Ô∏è Training Timeline\n\n```\nTime    Phase                               Duration\n------  ----------------------------------  ---------\n0:00    Cell 1: Setup                       2 min\n0:02    Cell 2: Training starts\n0:02    Load aggregated data                1 min\n0:03    Build Phase 1 features              15 min\n0:18    Build Phase 2-6 features            75 min\n1:33    Train Game: Moneyline               30 min\n2:03    Train Game: Spread                  30 min\n2:33    Train Player: Minutes               60 min\n3:33    Train Player: Points                70 min\n4:43    Train Player: Rebounds              60 min\n5:43    Train Player: Assists               60 min\n6:43    Train Player: Threes                50 min\n7:33    Training complete\n7:33    Cell 3: Validation                  1 min\n7:34    Cell 4: Summary                     10 sec\n7:35    Cell 5: Package + Download          1 min\n------\n7:36    DONE\n```\n\n**Total: ~7.5 hours on P100, ~8.5 hours on T4**\n\n---\n\n## üöÄ Quick Start Instructions\n\n### 1. Setup Kaggle Notebook\n- Create new notebook at kaggle.com/notebooks/new\n- In 'File' menu, select 'Import Notebook'\n- Upload this `.ipynb` file\n\n### 2. Add Data\n- In the right sidebar, click 'Add Data'\n- Search for `meeper`\n- Click 'Add'\n\n### 3. Enable GPU\n- In the right sidebar, find 'Accelerator'\n- Select 'GPU P100' (recommended) or 'GPU T4 x2'\n\n### 4. Run All\n- Click 'Run All' button\n- Training will take ~7-8 hours\n- You can close the browser, Kaggle will keep running"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}