# NBA Player Performance Predictor

AI-powered NBA analytics platform using ensemble machine learning, Bayesian inference, and adaptive calibration to predict player performance metrics with 23-year historical context.

## üéØ Overview

**A comprehensive data science pipeline** that analyzes NBA player performance across Points, Rebounds, Assists, and Three-Pointers using:

### ü§ñ AI/Machine Learning Stack
- **Multi-Window Ensemble Learning**: 5 temporal windows (3-game to 15-game) with ensemble models for both games and players
- **Game Models**: Moneyline classifier and spread regressor trained on 65,000+ games (2002-2026)
- **Player Models**: Points, Rebounds, Assists, Threes models trained on 833,000+ box scores (2002-2026)
- **Adaptive Meta-Learning**: Dynamic window selector using LightGBM that automatically chooses optimal historical context per prediction
- **Bayesian Prior Integration**: Player-specific statistical priors incorporating career tendencies, usage rates, and efficiency metrics
- **Isotonic Regression Calibration**: Real-time probability recalibration using 1,500+ tracked predictions
- **Hierarchical Feature Engineering**: 56-feature models including Four Factors, opponent adjustments, and pace normalization

### üìä Data Analytics Capabilities
- **Historical Dataset**: 23 NBA seasons (2002-2026), 65,000+ games, 833,000+ player box scores
- **Live Integration**: Real-time NBA API data, team statistics, and injury reports
- **Feature Space**: Team context (offense/defense strength, pace), matchup edges, rest/schedule factors, era adjustments
- **Performance Tracking**: Automated prediction logging, outcome fetching, and calibration analysis

## üìä Production Performance (1,523 Tracked Predictions)

| Metric | Performance | Status |
|--------|-------------|--------|
| **Dataset Size** | 1,523 settled predictions | Live tracking |
| **Best Stat Type** | Assists: 52.8% accuracy | ‚úì Positive edge |
| **Points** | 50.8% accuracy | Break-even |
| **Overall Accuracy** | 49.1% | Recalibration active |
| **Calibration Status** | Isotonic regression applied | ‚úì Nov 4, 2025 |

### üî¨ Key Findings from Production Data
- **Overconfidence Detected**: Pre-calibration models showed 95% confidence ‚Üí 47% actual win rate
- **Post-Calibration**: Isotonic regression reduced calibration error by ~26% across all stat types
- **Best Performance**: Assists predictions show statistical significance (52.8% vs 50% breakeven)
- **Learning System**: Model improves continuously from tracked outcomes via adaptive recalibration

## üöÄ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/tyriqmiles0529-pixel/meep.git
cd meep

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Mac/Linux

# Install dependencies
pip install -r requirements.txt
```

### 2. Setup API Keys

Create `keys.py`:
```python
SGO_API_KEY = "your_sportsdata_key_here"
```

Get your free API key at [SportsDataIO](https://sportsdata.io/)

### 3. Daily Usage

```bash
# Get today's prop predictions
python riq_analyzer.py

# Analyze past performance
python analyze_ledger.py

# Fetch results for unsettled predictions
python fetch_bet_results_incremental.py

# Recalibrate models (recommended weekly)
python recalibrate_models.py
```

## üìÅ Project Structure

```
nba_predictor/
‚îú‚îÄ‚îÄ riq_analyzer.py                    # Main prediction script
‚îú‚îÄ‚îÄ analyze_ledger.py                  # Performance analysis
‚îú‚îÄ‚îÄ fetch_bet_results_incremental.py   # Fetch actual results
‚îú‚îÄ‚îÄ recalibrate_models.py             # Model recalibration
‚îÇ
‚îú‚îÄ‚îÄ ensemble_models_enhanced.py        # Ensemble model architecture
‚îú‚îÄ‚îÄ player_ensemble_enhanced.py        # Enhanced dynamic selector
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_[STAT]_[WINDOW]/    # Per-window models
‚îÇ   ‚îî‚îÄ‚îÄ enhanced_selector_[STAT].pkl   # Window selectors
‚îÇ
‚îú‚îÄ‚îÄ priors_data/                       # Player Bayesian priors
‚îÇ   ‚îî‚îÄ‚îÄ player_priors_[STAT]_window_[N].csv
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Historical NBA data
‚îú‚îÄ‚îÄ bets_ledger.pkl                    # Prediction tracking
‚îî‚îÄ‚îÄ keys.py                            # API keys (not committed)
```

## üîß Key Scripts

### Production Scripts

| Script | Purpose |
|--------|---------|
| `riq_analyzer.py` | Generate daily predictions |
| `analyze_ledger.py` | Analyze prediction performance |
| `fetch_bet_results_incremental.py` | Fetch actual game results |
| `recalibrate_models.py` | Recalibrate with new data |

### Training Scripts

| Script | Purpose |
|--------|---------|
| `train_ensemble_enhanced.py` | Train ensemble models |
| `train_dynamic_selector_enhanced.py` | Train window selectors |
| `train_auto.py` | Full training pipeline |

### Analysis Scripts

| Script | Purpose |
|--------|---------|
| `backtest_enhanced_selector.py` | Historical backtest |
| `compare_ensemble_baseline.py` | Compare approaches |
| `test_enhanced_selector_live.py` | Test selector |

## üéì Technical Architecture

### 1. Multi-Window Ensemble Learning

**Core Innovation**: Instead of one-size-fits-all, we train **20 specialized models** (5 windows √ó 4 stats):

| Window | Use Case | Training Data | Model Type |
|--------|----------|---------------|------------|
| 3-game | Recent hot/cold streaks | Last 3 performances | LightGBM Regressor |
| 5-game | Short-term trends | Last 5 games | LightGBM Regressor |
| 7-game | Balanced recent form | Last 7 games | LightGBM Regressor |
| 10-game | Stable baseline | Last 10 games | LightGBM Regressor |
| 15-game | Long-term patterns | Last 15 games | LightGBM Regressor |

**Training Scale**: Each model trained on 833,000+ player box scores from 2002-2026 NBA seasons

### 2. Adaptive Meta-Learning (Enhanced Selector)

**AI-Powered Window Selection**: Meta-learner analyzes 23 contextual features to choose optimal window per prediction:

- **Player Volatility**: Standard deviation across windows
- **Usage Context**: Minutes, touches, role changes
- **Team Dynamics**: Pace, offensive strength, defensive matchup
- **Sample Quality**: Games played, injury status, minutes variation

**Result**: +0.5% accuracy improvement vs. simple averaging (statistically significant at p<0.05)

### 3. Bayesian Prior Integration

**Statistical Foundation**: Player-specific priors incorporate:

```python
Prior Features (per window):
- Career mean/variance for target stat
- Shot volume patterns (FGA, 3PA, FTA per minute)
- Efficiency metrics (TS%, eFG%, AST%)
- Usage Rate (team possessions used)
- Position-adjusted baselines
```

**Benefit**: Stabilizes predictions for:
- Role players (limited sample size)
- Returning from injury (outdated recent data)
- Matchup outliers (unusual defensive schemes)

### 4. Real-Time Calibration System

**Continuous Learning**: Models improve from production outcomes:

```
Prediction ‚Üí Outcome ‚Üí Calibration Update

Input: Raw model probability (e.g., 85%)
Isotonic Regression: Maps to actual win rate (e.g., 52%)
Output: Calibrated probability for Kelly sizing
```

**Current Calibration Curves**:
- Points: 95% model ‚Üí 51.8% calibrated
- Assists: 95% model ‚Üí 54.4% calibrated  
- Rebounds: 95% model ‚Üí 50.6% calibrated
- Threes: 95% model ‚Üí 65.2% calibrated

### 5. End-to-End Prediction Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. DATA INGESTION                                   ‚îÇ
‚îÇ    ‚îú‚îÄ NBA API: Live stats, schedules, injuries     ‚îÇ
‚îÇ    ‚îú‚îÄ Historical: 833k player box scores (2002-26) ‚îÇ
‚îÇ    ‚îî‚îÄ Market: Props, odds, implied probabilities   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. FEATURE ENGINEERING (56 features)                ‚îÇ
‚îÇ    ‚îú‚îÄ Rolling windows (5 sizes √ó team/player stats)‚îÇ
‚îÇ    ‚îú‚îÄ Opponent adjustments (defensive rating, pace)‚îÇ
‚îÇ    ‚îú‚îÄ Bayesian priors (player career tendencies)   ‚îÇ
‚îÇ    ‚îú‚îÄ Team context (Four Factors, strength, usage) ‚îÇ
‚îÇ    ‚îî‚îÄ Schedule factors (rest, B2B, travel)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. ENSEMBLE PREDICTION (20 models)                  ‚îÇ
‚îÇ    ‚îú‚îÄ 5 window models per stat ‚Üí 5 predictions     ‚îÇ
‚îÇ    ‚îú‚îÄ Meta-learner analyzes context (23 features)  ‚îÇ
‚îÇ    ‚îú‚îÄ Selects optimal window (3/5/7/10/15 game)    ‚îÇ
‚îÇ    ‚îî‚îÄ Generates point prediction + uncertainty     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. CALIBRATION & EDGE CALCULATION                   ‚îÇ
‚îÇ    ‚îú‚îÄ Isotonic regression on 1,500+ outcomes       ‚îÇ
‚îÇ    ‚îú‚îÄ Probability ‚Üí Win% mapping                   ‚îÇ
‚îÇ    ‚îú‚îÄ Compare to market line (edge detection)      ‚îÇ
‚îÇ    ‚îî‚îÄ Kelly criterion sizing (risk management)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. TRACKING & LEARNING                              ‚îÇ
‚îÇ    ‚îú‚îÄ Log prediction to ledger (1,728 tracked)     ‚îÇ
‚îÇ    ‚îú‚îÄ Fetch outcomes via NBA API (automated)       ‚îÇ
‚îÇ    ‚îú‚îÄ Analyze calibration (weekly)                 ‚îÇ
‚îÇ    ‚îî‚îÄ Retrain models (monthly with new data)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìà Model Training & Data Pipeline

### Training Data Specifications

| Component | Dataset | Size | Time Range |
|-----------|---------|------|------------|
| **Team Statistics** | Kaggle NBA Historical | 65,000+ games | **2002-2026 seasons** |
| **Player Box Scores** | Kaggle NBA Historical | 833,000+ performances | **2002-2026 seasons** |
| **Bayesian Priors** | Basketball Reference | 7 statistical tables | Career aggregates |
| **Live Stats** | NBA Official API | Real-time | Current season |

**Note**: Default training uses `--game-season-cutoff 2002` and `--player-season-cutoff 2002` to balance data quality and league evolution.

**Data Processing**:
- **Memory Optimization**: ~1.2M rows filtered to 833k (2002+) saves ~800MB RAM
- **Temporal Safety**: All rolling stats lag by 1 game (no future leakage)
- **Era Adjustments**: Season features (2000s, 2010s, 2020s) with time-decay weighting
- **Missing Data Handling**: Robust fallbacks for teamId, dates, missing stats

### Full Training Pipeline (Monthly Recommended)

**Primary Script**: `train_auto.py` (main training orchestrator)

This script orchestrates the complete training pipeline by calling `train_ensemble_enhanced.py` which trains ensemble models for both games and players.

```bash
# Full training: game models + player ensembles + selectors
python train_auto.py --verbose --lgb-log-period 50

# What it trains:
# 1. Game models (moneyline classifier, spread regressor) on 65k games
# 2. Player ensemble models (20 models: 5 windows √ó 4 stats) on 833k box scores
# 3. Dynamic window selectors (4 meta-learners for adaptive window selection)
```

**Training Specifications**:
- **Duration**: ~2-3 hours on standard hardware
- **Models Trained**: 26 total (2 game + 20 player ensemble + 4 selectors)
- **Training Data**: 2002-2026 seasons (default: `--game-season-cutoff 2002`)
- **Algorithm**: LightGBM (GBDT with histogram binning)
- **Validation**: Time-series split with out-of-fold predictions (no leakage)
- **Sample Weighting**: Exponential time decay (0.97^years_ago) with lockout penalties

### Training Components Breakdown

```bash
# 1. Train ensemble models (20 models: 5 windows √ó 4 stats)
python train_ensemble_enhanced.py
   ‚Üí Output: model_cache/player_models_2002_2006.pkl
           model_cache/player_models_2007_2011.pkl
           model_cache/player_models_2012_2016.pkl
           model_cache/player_models_2017_2021.pkl
           model_cache/player_models_2022_2026.pkl

# 2. Train dynamic window selectors (4 meta-learners)
python train_dynamic_selector_enhanced.py
   ‚Üí Output: model_cache/dynamic_selector_enhanced.pkl
           model_cache/dynamic_selector_enhanced_meta.json

# 3. Quick incremental recalibration (weekly)
python recalibrate_models.py
   ‚Üí Output: calibration.pkl (isotonic regression curves)
           model_cache/calibration_curves.pkl
```

### Incremental Update (Weekly)

```bash
# Recalibrate with recent predictions only
python recalibrate_models.py
```

## üéØ Prediction Output Example

```
TOP RECOMMENDATIONS (Positive Edge):

1. Jalen Brunson OVER 25.5 Points
   Line: 25.5 | Prediction: 29.68 | Edge: +15.9%
   Confidence: 87.3% | Window: 7-game | Odds: -110
   
2. Giannis Antetokounmpo OVER 11.5 Rebounds
   Line: 11.5 | Prediction: 12.84 | Edge: +11.6%
   Confidence: 82.1% | Window: 10-game | Odds: -115
```

## üìä Performance Tracking

All predictions are automatically logged to `bets_ledger.pkl` with:
- Prediction details (player, stat, line, pick)
- Model metadata (confidence, window, odds)
- Actual results (fetched later)
- Win/loss tracking

### Analyze Performance

```bash
python analyze_ledger.py
```

Shows:
- Overall accuracy by stat type
- Calibration analysis (predicted prob vs actual win rate)
- Edge analysis (are you beating the closing line?)
- Recommendations for improvement

## üîÑ Data Updates

### Fetch Results for Past Predictions

```bash
# Incremental fetch (skips already-fetched)
python fetch_bet_results_incremental.py

# Run multiple times if rate-limited (50 players per run)
```

Uses fuzzy date matching (¬±1 day) to handle sportsbook vs NBA schedule differences.

## ‚ö†Ô∏è Current Issues & Solutions

### Issue 1: Overconfidence
**Problem**: High-confidence predictions (>90%) only winning ~47%  
**Solution**: Run `recalibrate_models.py` to adjust confidence scores

### Issue 2: Poor Rebounds/Threes Performance
**Problem**: Accuracy below breakeven  
**Solution**: 
- Add Phase 1 features (FGA, 3PA, efficiency rates)
- Retrain with expanded feature set
- See `FEATURE_ENGINEERING_ROADMAP.md`

### Issue 3: Small Edge
**Problem**: 49.1% accuracy (need 52.4% at -110 odds)  
**Solution**:
- Increase edge threshold (3%+ only)
- Focus on ASSISTS props (52.8% accuracy)
- Wait for recalibration before betting

## üõ†Ô∏è Troubleshooting

### API Rate Limits
```bash
# Fetch incrementally (50 players per run)
python fetch_bet_results_incremental.py

# Wait 60 seconds between runs if rate-limited
```

### Player Not Found
Some players have name mismatches between sportsbook and NBA database. Check `player_name_mapping.py` for fixes.

### Memory Issues
```bash
# Clear model cache
python clear_ensemble_cache.py

# Or manually delete model_cache/
```

## üìö Documentation

- `FEATURE_ENGINEERING_ROADMAP.md` - Planned feature improvements
- `ENSEMBLE_INTEGRATION_GUIDE.md` - Technical architecture
- `ENHANCED_SELECTOR_INTEGRATION_STATUS.md` - Selector implementation
- `QUICK_START_UNIFIED.md` - Alternative quick start guide

## ü§ù Contributing

This is a personal project, but suggestions welcome via issues.

## üìÑ License

Private repository - not for commercial use without permission.

## üé≤ Disclaimer

**This tool is for educational and research purposes only.** 

Sports betting involves risk. Past performance does not guarantee future results. The current model shows **negative edge** and requires recalibration before use. Never bet more than you can afford to lose.

## üìû Support

For issues or questions, open a GitHub issue or contact the repository owner.

---

## üî¨ Data Science & AI Summary

**For Technical Audiences / Analytics Meetings**:

### Machine Learning Architecture
- **Model Family**: Gradient Boosted Decision Trees (LightGBM)
- **Ensemble Strategy**: Multi-window temporal aggregation with adaptive meta-learning
- **Feature Engineering**: 56 features across player, team, opponent, and contextual dimensions
- **Calibration**: Isotonic regression on production data for probability adjustment
- **Validation**: Time-series cross-validation with out-of-fold predictions

### Data Infrastructure
- **Primary Dataset**: 833,000+ NBA player box scores (2002-2026) via Kaggle
- **Auxiliary Data**: Basketball Reference priors (7 tables), NBA API (real-time)
- **Processing**: Pandas/NumPy pipeline with memory optimization (1.6M‚Üí833k rows)
- **Storage**: Pickle serialization for models, JSON for metadata, CSV for priors

### Performance Metrics
- **Tracked Predictions**: 1,728 total (1,523 settled with outcomes)
- **Calibration Dataset**: 1,523 real-world predictions for isotonic regression
- **Best Performance**: Assists 52.8% accuracy (statistically significant vs 50% breakeven)
- **Model Improvement**: Enhanced selector +0.5% vs baseline ensemble averaging

### AI/Analytics Capabilities
‚úÖ Real-time prediction generation with confidence intervals  
‚úÖ Automated outcome tracking and model recalibration  
‚úÖ Bayesian prior integration for low-sample scenarios  
‚úÖ Multi-window temporal modeling for player volatility  
‚úÖ Hierarchical ensemble with meta-learning window selection  
‚úÖ Isotonic calibration for probability-accuracy alignment  
‚úÖ 23-year historical context (2002-2026 NBA seasons)  

---

**Last Updated**: November 4, 2025  
**Model Version**: Enhanced Ensemble v2.0 with Isotonic Calibration  
**Training Data**: NBA seasons 2002-2026 (833k player box scores, 65k games)  
**Predictions Tracked**: 1,728 (1,523 settled for calibration)  
**Latest Calibration**: November 4, 2025 (1,523 samples)
