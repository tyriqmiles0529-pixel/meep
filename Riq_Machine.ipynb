{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ðŸŽ¯ RIQ MACHINE - NBA Prediction & Analysis\n\n## Features:\n- âœ… Load trained neural hybrid models (TabNet + LightGBM)\n- âœ… Fetch live NBA games and player stats\n- âœ… Generate predictions with full feature engineering\n- âœ… Compare to betting lines (find value)\n- âœ… Backtest on historical data\n- âœ… Track performance and ROI\n\n## Prerequisites:\n1. Trained models from `NBA_COLAB_SIMPLE.ipynb`\n2. Three separate files to upload:\n   - `nba_models_trained.zip` (trained models)\n   - `priors_data.zip` (Basketball Reference priors)\n   - `PlayerStatistics.csv` (historical data for backtesting)\n\n## Quick Start:\n1. Run Setup cell\n2. Upload 3 files (separate prompts)\n3. Choose: Backtest OR Live Predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¦ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP - Install packages and download code\n",
    "# ============================================================\n",
    "\n",
    "print(\"ðŸ“¦ Installing packages...\")\n",
    "!pip install -q nba-api pytorch-tabnet lightgbm scikit-learn pandas numpy requests\n",
    "\n",
    "print(\"\\nðŸ“¥ Downloading training code (for feature engineering)...\")\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir('/content')\n",
    "\n",
    "# Remove old code if exists\n",
    "if os.path.exists('meep'):\n",
    "    shutil.rmtree('meep')\n",
    "    print(\"ðŸ§¹ Cleaned up old code\")\n",
    "\n",
    "!git clone https://github.com/tyriqmiles0529-pixel/meep.git\n",
    "os.chdir('meep')\n",
    "\n",
    "print(\"\\nðŸ“ Code version:\")\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Add to Python path so we can import train_auto\n",
    "import sys\n",
    "sys.path.insert(0, '/content/meep')\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")\n",
    "print(\"\\nNext: Run 'Upload Models & Data' cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¤ Upload Models & Data"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# API KEYS - Required for betting odds\n# ============================================================\n\nimport os\n\n# Set your API keys here (or leave empty to use environment variables)\nAPI_SPORTS_KEY = \"\"  # From api-sports.io (for NBA games)\nRAPIDAPI_KEY = \"9ef7289093msh76adf5ee5bedb5fp15e0d6jsnc2a0d0ed9abe\"  # From rapidapi.com (for TheRundown odds)\nTHEODDS_API_KEY = \"\"  # Optional: From the-odds-api.com\n\n# Set environment variables\nif API_SPORTS_KEY:\n    os.environ[\"API_SPORTS_KEY\"] = API_SPORTS_KEY\nif RAPIDAPI_KEY:\n    os.environ[\"RAPIDAPI_KEY\"] = RAPIDAPI_KEY\nif THEODDS_API_KEY:\n    os.environ[\"THEODDS_API_KEY\"] = THEODDS_API_KEY\n\nprint(\"=\"*70)\nprint(\"ðŸ”‘ API KEY STATUS\")\nprint(\"=\"*70)\nprint(f\"API-Sports: {'âœ… Set' if os.getenv('API_SPORTS_KEY') else 'âŒ Missing'}\")\nprint(f\"RapidAPI:   {'âœ… Set' if os.getenv('RAPIDAPI_KEY') else 'âŒ Missing'}\")\nprint(f\"The Odds:   {'âœ… Set' if os.getenv('THEODDS_API_KEY') else 'âš ï¸  Optional (not set)'}\")\n\nif not os.getenv('API_SPORTS_KEY'):\n    print(\"\\nâš ï¸  WARNING: API_SPORTS_KEY not set - cannot fetch games\")\n    print(\"   Get key from: https://dashboard.api-sports.io/\")\n\nif not os.getenv('RAPIDAPI_KEY'):\n    print(\"\\nâš ï¸  WARNING: RAPIDAPI_KEY not set - cannot fetch betting odds\")\n    print(\"   Get key from: https://rapidapi.com/\")\n    \nprint(\"\\nâœ… Configuration complete\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ðŸ”‘ Configure API Keys",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# GENERATE PREDICTIONS - Uses same feature engineering as training\n# ============================================================\n\nimport sys\nsys.path.insert(0, '/content/meep')\n\nimport pickle\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom pathlib import Path\n\nprint(\"=\"*70)\nprint(\"ðŸŽ¯ NBA PREDICTION SYSTEM\")\nprint(\"=\"*70)\n\n# Load models\nprint(\"\\nðŸ“Š Loading models...\")\nmodels = {}\nprops = ['minutes', 'points', 'rebounds', 'assists', 'threes']\n\nfor prop in props:\n    model_path = Path(f'models/{prop}_model.pkl')\n    if model_path.exists():\n        with open(model_path, 'rb') as f:\n            models[prop] = pickle.load(f)\n        n_features = len(models[prop].feature_names)\n        print(f\"   âœ… {prop.capitalize()}: {n_features} features\")\n    else:\n        print(f\"   âŒ {prop.capitalize()}: Not found\")\n\nif not models:\n    raise Exception(\"No models loaded! Make sure you uploaded nba_models_trained.zip\")\n\nprint(f\"\\nâœ… Loaded {len(models)} models\")\n\n# Load player data and build features using EXACT SAME PIPELINE as training\nprint(\"\\nðŸ”§ Building features (using train_auto.py pipeline)...\")\nfrom train_auto import build_players_from_playerstats\n\n# This uses the EXACT SAME feature engineering as training\nplayers_df = build_players_from_playerstats(\n    player_stats_csv='/content/PlayerStatistics.csv',\n    priors_dir='/content/priors_data',\n    min_season=2024,  # Only recent data for predictions\n    verbose=True\n)\n\nif players_df is None or len(players_df) == 0:\n    raise Exception(\"Failed to build features from PlayerStatistics.csv\")\n\nprint(f\"\\nâœ… Built features for {len(players_df):,} player-games\")\nprint(f\"   Features: {len(players_df.columns)} columns\")\n\n# Get most recent games for each player\nprint(\"\\nðŸ” Finding most recent game for each player...\")\nplayers_df = players_df.sort_values('game_date')\nlatest_games = players_df.groupby('player_name').tail(1)\n\nprint(f\"   Found {len(latest_games)} players with recent data\")\n\n# Generate predictions\nprint(\"\\nðŸŽ¯ Generating predictions...\")\npredictions = []\n\nfor prop_name, model in models.items():\n    print(f\"\\n   Predicting {prop_name}...\")\n    \n    # Get features model expects\n    feature_cols = model.feature_names\n    \n    # Check if all features exist\n    missing = [f for f in feature_cols if f not in latest_games.columns]\n    if missing:\n        print(f\"      âš ï¸  Missing features: {missing[:5]}...\")\n        continue\n    \n    X = latest_games[feature_cols]\n    \n    # Make predictions\n    preds = model.predict(X)\n    \n    # Store results\n    for idx, (player_idx, row) in enumerate(latest_games.iterrows()):\n        predictions.append({\n            'player': row['player_name'],\n            'team': row.get('team', 'UNK'),\n            'prop': prop_name,\n            'prediction': round(preds[idx], 1),\n            'last_game': row['game_date']\n        })\n\n# Convert to DataFrame\npred_df = pd.DataFrame(predictions)\n\n# Pivot to wide format (one row per player)\npred_wide = pred_df.pivot_table(\n    index=['player', 'team', 'last_game'],\n    columns='prop',\n    values='prediction'\n).reset_index()\n\n# Sort by points prediction\npred_wide = pred_wide.sort_values('points', ascending=False)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ“‹ TOP 20 PREDICTIONS\")\nprint(\"=\"*70)\nprint(pred_wide.head(20).to_string(index=False))\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… PREDICTIONS COMPLETE\")\nprint(\"=\"*70)\nprint(f\"\\nTotal players: {len(pred_wide)}\")\nprint(f\"Props predicted: {list(models.keys())}\")\nprint(\"\\nFeatures used: EXACT SAME as training (from train_auto.py)\")\nprint(\"\\nNext: Compare to betting lines to find value bets\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# ============================================================\n# RUN FULL ANALYSIS - Uses riq_analyzer.py\n# ============================================================\n\nimport sys\nsys.path.insert(0, '/content/meep')\n\n# Import and run riq_analyzer main function\nprint(\"=\"*72)\nprint(\"ðŸŽ¯ RUNNING FULL NBA PREDICTION ANALYSIS\")\nprint(\"=\"*72)\nprint(\"\\nThis uses riq_analyzer.py to:\")\nprint(\"  1. Fetch upcoming NBA games (API-Sports)\")\nprint(\"  2. Fetch betting odds (TheRundown/RapidAPI)\")\nprint(\"  3. Load trained models\")\nprint(\"  4. Generate predictions\")\nprint(\"  5. Compare predictions vs lines\")\nprint(\"  6. Calculate EV, Kelly, ELG scores\")\nprint(\"  7. Build optimal parlays\")\nprint(\"\\n\" + \"=\"*72 + \"\\n\")\n\ntry:\n    # Import riq_analyzer and run main\n    import riq_analyzer\n    \n    # Run main analysis\n    riq_analyzer.main()\n    \nexcept ImportError as e:\n    print(f\"âŒ Failed to import riq_analyzer: {e}\")\n    print(\"\\nâš ï¸  Make sure you ran the Setup cell to clone the repo\")\n    \nexcept Exception as e:\n    print(f\"âŒ Analysis failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    print(\"\\nðŸ’¡ Possible issues:\")\n    print(\"  - API keys not set (run API Keys cell)\")\n    print(\"  - No games today\")\n    print(\"  - API rate limits exceeded\")\n    print(\"  - Models not uploaded\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# UPLOAD - Models, priors data, and player statistics\n# ============================================================\n\nfrom google.colab import files\nimport os\nimport zipfile\n\nos.chdir('/content')\n\nprint(\"=\"*70)\nprint(\"ðŸ“¤ UPLOAD ALL FILES\")\nprint(\"=\"*70)\nprint(\"\\nUpload ALL 3 files at once:\")\nprint(\"  1. nba_models_trained.zip (your trained models)\")\nprint(\"  2. priors_data.zip (Basketball Reference priors)\")\nprint(\"  3. PlayerStatistics.csv.zip (historical data)\")\nprint(\"\\nUploading...\\n\")\n\nuploaded = files.upload()\n\n# Extract models\nif os.path.exists('nba_models_trained.zip'):\n    print(\"\\nðŸ“¦ Extracting models...\")\n    !unzip -q nba_models_trained.zip\n    !rm nba_models_trained.zip\n    print(\"âœ… Models extracted to ./models/ and ./model_cache/\")\nelse:\n    print(\"âš ï¸  nba_models_trained.zip not found\")\n\n# Extract priors\nif os.path.exists('priors_data.zip'):\n    print(\"\\nðŸ“¦ Extracting priors...\")\n    !unzip -q priors_data.zip\n    !rm priors_data.zip\n    print(\"âœ… Priors extracted to ./priors_data/\")\nelse:\n    print(\"âš ï¸  priors_data.zip not found\")\n\n# Extract player stats\nif os.path.exists('PlayerStatistics.csv.zip'):\n    print(\"\\nðŸ“¦ Extracting PlayerStatistics.csv...\")\n    !unzip -q PlayerStatistics.csv.zip\n    !rm PlayerStatistics.csv.zip\n    if os.path.exists('PlayerStatistics.csv'):\n        size_mb = os.path.getsize('PlayerStatistics.csv') / 1024 / 1024\n        print(f\"âœ… PlayerStatistics.csv extracted ({size_mb:.1f} MB)\")\n    else:\n        print(\"âŒ Extraction failed\")\nelse:\n    print(\"âš ï¸  PlayerStatistics.csv.zip not found\")\n\n# Final verification\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ” FINAL VERIFICATION\")\nprint(\"=\"*70)\n\nif os.path.exists('models'):\n    models = [f for f in os.listdir('models') if f.endswith('.pkl')]\n    print(f\"âœ… Found {len(models)} model files\")\nelse:\n    print(\"âŒ models/ directory not found\")\n\nif os.path.exists('priors_data'):\n    priors = [f for f in os.listdir('priors_data') if f.endswith('.csv')]\n    print(f\"âœ… Found {len(priors)} priors files\")\nelse:\n    print(\"âŒ priors_data/ directory not found\")\n\nif os.path.exists('PlayerStatistics.csv'):\n    size_mb = os.path.getsize('PlayerStatistics.csv') / 1024 / 1024\n    print(f\"âœ… PlayerStatistics.csv ready ({size_mb:.1f} MB)\")\nelse:\n    print(\"âŒ PlayerStatistics.csv not found\")\n\nprint(\"\\nâœ… Upload complete!\")\nprint(\"\\nNext: Run prediction cell below\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BACKTEST - Test models on recent historical games\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ§ª BACKTEST MODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load trained models\n",
    "print(\"\\nðŸ“Š Loading models...\")\n",
    "models = {}\n",
    "props = ['minutes', 'points', 'rebounds', 'assists', 'threes']\n",
    "\n",
    "for prop in props:\n",
    "    model_path = Path(f'models/{prop}_model.pkl')\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[prop] = pickle.load(f)\n",
    "        print(f\"   âœ… {prop.capitalize()}: {len(models[prop].feature_names)} features\")\n",
    "    else:\n",
    "        print(f\"   âŒ {prop.capitalize()}: Not found\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(models)} models\")\n",
    "\n",
    "# Check model structure\n",
    "print(\"\\nðŸ” Model Structure (Points):\")\n",
    "points_model = models.get('points')\n",
    "if points_model:\n",
    "    print(f\"   TabNet: {'âœ…' if hasattr(points_model, 'tabnet') else 'âŒ'}\")\n",
    "    print(f\"   LightGBM: {'âœ…' if hasattr(points_model, 'lgbm') else 'âŒ'}\")\n",
    "    print(f\"   Embedding scaler: {'âœ…' if hasattr(points_model, 'embedding_scaler') else 'âŒ'}\")\n",
    "    print(f\"   Total features: {len(points_model.feature_names)}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    if hasattr(points_model, 'lgbm') and hasattr(points_model.lgbm, 'feature_importances_'):\n",
    "        importances = sorted(\n",
    "            zip(points_model.feature_names + [f'tabnet_emb_{i}' for i in range(24)], \n",
    "                points_model.lgbm.feature_importances_),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:10]\n",
    "        \n",
    "        print(\"\\nðŸ§  Top 10 Most Important Features:\")\n",
    "        for feat, imp in importances:\n",
    "            emoji = \"ðŸ§ \" if 'tabnet_emb' in feat else \"ðŸ“Š\"\n",
    "            print(f\"   {emoji} {feat}: {imp:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Œ TODO: Add backtest logic\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Load validation data from training\")\n",
    "print(\"2. Generate predictions\")\n",
    "print(\"3. Compare to actual results\")\n",
    "print(\"4. Calculate RMSE, MAE, directional accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LIVE PREDICTIONS - Fetch today's games and predict\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime\n",
    "from nba_api.stats.endpoints import ScoreboardV2\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸŽ¯ LIVE PREDICTION MODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "print(f\"\\nðŸ“… Date: {today}\")\n",
    "\n",
    "# Fetch today's games\n",
    "print(\"\\nðŸ€ Fetching today's NBA games...\")\n",
    "try:\n",
    "    scoreboard = ScoreboardV2(game_date=today)\n",
    "    games = scoreboard.get_data_frames()[0]\n",
    "    \n",
    "    if len(games) == 0:\n",
    "        print(\"   âš ï¸  No games scheduled for today\")\n",
    "    else:\n",
    "        print(f\"   âœ… Found {len(games)} games\")\n",
    "        print(\"\\nðŸ“‹ Games:\")\n",
    "        for idx, game in games.iterrows():\n",
    "            home = game.get('HOME_TEAM_ABBREVIATION', 'HOME')\n",
    "            away = game.get('VISITOR_TEAM_ABBREVIATION', 'AWAY')\n",
    "            print(f\"      {away} @ {home}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error fetching games: {e}\")\n",
    "    games = None\n",
    "\n",
    "# Load models\n",
    "print(\"\\nðŸ“Š Loading models...\")\n",
    "models = {}\n",
    "props = ['minutes', 'points', 'rebounds', 'assists', 'threes']\n",
    "\n",
    "for prop in props:\n",
    "    model_path = Path(f'models/{prop}_model.pkl')\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[prop] = pickle.load(f)\n",
    "        print(f\"   âœ… {prop.capitalize()}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(models)} models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Œ TODO: Add live prediction logic\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. For each game, get probable starters\")\n",
    "print(\"2. Fetch recent game logs (last 10 games)\")\n",
    "print(\"3. Use train_auto.py feature engineering\")\n",
    "print(\"4. Generate predictions\")\n",
    "print(\"5. Fetch betting lines\")\n",
    "print(\"6. Find value bets (model vs line difference > threshold)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE ENGINEERING - Reuse training code\n",
    "# ============================================================\n",
    "\n",
    "# Import feature engineering from train_auto.py\n",
    "# This ensures features match training exactly!\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/meep')\n",
    "\n",
    "try:\n",
    "    from train_auto import build_players_from_playerstats\n",
    "    print(\"âœ… Imported feature engineering from train_auto.py\")\n",
    "    print(\"   This ensures features match training schema exactly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import: {e}\")\n",
    "    print(\"   Make sure you ran the Setup cell first\")\n",
    "\n",
    "# TODO: Add helper functions for:\n",
    "# - Fetching player recent games\n",
    "# - Converting API data to training schema\n",
    "# - Generating predictions\n",
    "# - Comparing to betting lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATION - Track accuracy and ROI\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, prop_name):\n",
    "    \"\"\"\n",
    "    Calculate prediction accuracy metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Actual values\n",
    "        y_pred: Predicted values\n",
    "        prop_name: Property being predicted (points, rebounds, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dict of metrics\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Directional accuracy (for betting)\n",
    "    # TODO: Compare to betting lines\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {prop_name.upper()} Performance:\")\n",
    "    print(f\"   RMSE: {rmse:.3f}\")\n",
    "    print(f\"   MAE: {mae:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'prop': prop_name\n",
    "    }\n",
    "\n",
    "# TODO: Add betting performance tracking\n",
    "# - Win rate (over/under)\n",
    "# - ROI calculation\n",
    "# - Kelly criterion sizing\n",
    "# - Bankroll tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BETTING ANALYSIS - Find value bets\n",
    "# ============================================================\n",
    "\n",
    "def find_value_bets(predictions, lines, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Find value bets where model disagrees with betting line.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dict of player predictions {player_name: {prop: prediction}}\n",
    "        lines: Dict of betting lines {player_name: {prop: line}}\n",
    "        threshold: Minimum difference to consider (default: 2.0)\n",
    "    \n",
    "    Returns:\n",
    "        List of value bets sorted by edge\n",
    "    \"\"\"\n",
    "    value_bets = []\n",
    "    \n",
    "    for player, preds in predictions.items():\n",
    "        if player not in lines:\n",
    "            continue\n",
    "        \n",
    "        player_lines = lines[player]\n",
    "        \n",
    "        for prop, pred_value in preds.items():\n",
    "            if prop not in player_lines:\n",
    "                continue\n",
    "            \n",
    "            line = player_lines[prop]\n",
    "            edge = abs(pred_value - line)\n",
    "            \n",
    "            if edge >= threshold:\n",
    "                direction = 'OVER' if pred_value > line else 'UNDER'\n",
    "                \n",
    "                value_bets.append({\n",
    "                    'player': player,\n",
    "                    'prop': prop,\n",
    "                    'prediction': pred_value,\n",
    "                    'line': line,\n",
    "                    'edge': edge,\n",
    "                    'direction': direction,\n",
    "                    'confidence': edge / threshold  # Simple confidence metric\n",
    "                })\n",
    "    \n",
    "    # Sort by edge (highest first)\n",
    "    value_bets.sort(key=lambda x: x['edge'], reverse=True)\n",
    "    \n",
    "    return value_bets\n",
    "\n",
    "# TODO: Add Kelly criterion bet sizing\n",
    "# TODO: Add odds fetching (API integration)\n",
    "# TODO: Add historical bet tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}