{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ðŸŽ¯ RIQ MACHINE - NBA Prediction & Analysis\n\n## Features:\n- âœ… Load trained neural hybrid models (TabNet + LightGBM)\n- âœ… Fetch live NBA games and player stats\n- âœ… Generate predictions with full feature engineering\n- âœ… Compare to betting lines (find value)\n- âœ… Backtest on historical data\n- âœ… Track performance and ROI\n\n## Prerequisites:\n1. Trained models from `NBA_COLAB_SIMPLE.ipynb`\n2. Upload `nba_models_trained.zip` to this Colab\n3. Upload `priors_data.zip` (for feature engineering)\n4. Upload `PlayerStatistics.csv` (for backtest data)\n\n## Quick Start:\n1. Run Setup cell\n2. Upload model files + data\n3. Choose: Backtest OR Live Predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¦ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP - Install packages and download code\n",
    "# ============================================================\n",
    "\n",
    "print(\"ðŸ“¦ Installing packages...\")\n",
    "!pip install -q nba-api pytorch-tabnet lightgbm scikit-learn pandas numpy requests\n",
    "\n",
    "print(\"\\nðŸ“¥ Downloading training code (for feature engineering)...\")\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.chdir('/content')\n",
    "\n",
    "# Remove old code if exists\n",
    "if os.path.exists('meep'):\n",
    "    shutil.rmtree('meep')\n",
    "    print(\"ðŸ§¹ Cleaned up old code\")\n",
    "\n",
    "!git clone https://github.com/tyriqmiles0529-pixel/meep.git\n",
    "os.chdir('meep')\n",
    "\n",
    "print(\"\\nðŸ“ Code version:\")\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Add to Python path so we can import train_auto\n",
    "import sys\n",
    "sys.path.insert(0, '/content/meep')\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")\n",
    "print(\"\\nNext: Run 'Upload Models & Data' cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“¤ Upload Models & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UPLOAD - Models and priors data\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "os.chdir('/content')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“¤ UPLOAD REQUIRED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou need 2 files:\")\n",
    "print(\"  1. nba_models_trained.zip (your trained models)\")\n",
    "print(\"  2. priors_data.zip (for feature engineering)\")\n",
    "print(\"\\nUploading...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\nðŸ“¦ Extracting files...\")\n",
    "\n",
    "# Extract models\n",
    "if os.path.exists('nba_models_trained.zip'):\n",
    "    !unzip -q nba_models_trained.zip\n",
    "    !rm nba_models_trained.zip\n",
    "    print(\"âœ… Models extracted to ./models/ and ./model_cache/\")\n",
    "else:\n",
    "    print(\"âš ï¸  nba_models_trained.zip not found\")\n",
    "\n",
    "# Extract priors\n",
    "if os.path.exists('priors_data.zip'):\n",
    "    !unzip -q priors_data.zip\n",
    "    !rm priors_data.zip\n",
    "    print(\"âœ… Priors extracted to ./priors_data/\")\n",
    "else:\n",
    "    print(\"âš ï¸  priors_data.zip not found\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nðŸ” Verification:\")\n",
    "if os.path.exists('models'):\n",
    "    models = [f for f in os.listdir('models') if f.endswith('.pkl')]\n",
    "    print(f\"   âœ… Found {len(models)} model files\")\n",
    "    for m in models:\n",
    "        print(f\"      - {m}\")\n",
    "else:\n",
    "    print(\"   âŒ models/ directory not found\")\n",
    "\n",
    "if os.path.exists('priors_data'):\n",
    "    priors = [f for f in os.listdir('priors_data') if f.endswith('.csv')]\n",
    "    print(f\"   âœ… Found {len(priors)} priors files\")\n",
    "else:\n",
    "    print(\"   âŒ priors_data/ directory not found\")\n",
    "\n",
    "print(\"\\nâœ… Upload complete!\")\n",
    "print(\"\\nNext: Choose Backtest OR Live Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§ª Option A: Backtest (Test on Historical Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BACKTEST - Test models on recent historical games\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ§ª BACKTEST MODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load trained models\n",
    "print(\"\\nðŸ“Š Loading models...\")\n",
    "models = {}\n",
    "props = ['minutes', 'points', 'rebounds', 'assists', 'threes']\n",
    "\n",
    "for prop in props:\n",
    "    model_path = Path(f'models/{prop}_model.pkl')\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[prop] = pickle.load(f)\n",
    "        print(f\"   âœ… {prop.capitalize()}: {len(models[prop].feature_names)} features\")\n",
    "    else:\n",
    "        print(f\"   âŒ {prop.capitalize()}: Not found\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(models)} models\")\n",
    "\n",
    "# Check model structure\n",
    "print(\"\\nðŸ” Model Structure (Points):\")\n",
    "points_model = models.get('points')\n",
    "if points_model:\n",
    "    print(f\"   TabNet: {'âœ…' if hasattr(points_model, 'tabnet') else 'âŒ'}\")\n",
    "    print(f\"   LightGBM: {'âœ…' if hasattr(points_model, 'lgbm') else 'âŒ'}\")\n",
    "    print(f\"   Embedding scaler: {'âœ…' if hasattr(points_model, 'embedding_scaler') else 'âŒ'}\")\n",
    "    print(f\"   Total features: {len(points_model.feature_names)}\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    if hasattr(points_model, 'lgbm') and hasattr(points_model.lgbm, 'feature_importances_'):\n",
    "        importances = sorted(\n",
    "            zip(points_model.feature_names + [f'tabnet_emb_{i}' for i in range(24)], \n",
    "                points_model.lgbm.feature_importances_),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:10]\n",
    "        \n",
    "        print(\"\\nðŸ§  Top 10 Most Important Features:\")\n",
    "        for feat, imp in importances:\n",
    "            emoji = \"ðŸ§ \" if 'tabnet_emb' in feat else \"ðŸ“Š\"\n",
    "            print(f\"   {emoji} {feat}: {imp:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Œ TODO: Add backtest logic\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Load validation data from training\")\n",
    "print(\"2. Generate predictions\")\n",
    "print(\"3. Compare to actual results\")\n",
    "print(\"4. Calculate RMSE, MAE, directional accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Option B: Live Predictions (Today's Games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LIVE PREDICTIONS - Fetch today's games and predict\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime\n",
    "from nba_api.stats.endpoints import ScoreboardV2\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸŽ¯ LIVE PREDICTION MODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "print(f\"\\nðŸ“… Date: {today}\")\n",
    "\n",
    "# Fetch today's games\n",
    "print(\"\\nðŸ€ Fetching today's NBA games...\")\n",
    "try:\n",
    "    scoreboard = ScoreboardV2(game_date=today)\n",
    "    games = scoreboard.get_data_frames()[0]\n",
    "    \n",
    "    if len(games) == 0:\n",
    "        print(\"   âš ï¸  No games scheduled for today\")\n",
    "    else:\n",
    "        print(f\"   âœ… Found {len(games)} games\")\n",
    "        print(\"\\nðŸ“‹ Games:\")\n",
    "        for idx, game in games.iterrows():\n",
    "            home = game.get('HOME_TEAM_ABBREVIATION', 'HOME')\n",
    "            away = game.get('VISITOR_TEAM_ABBREVIATION', 'AWAY')\n",
    "            print(f\"      {away} @ {home}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error fetching games: {e}\")\n",
    "    games = None\n",
    "\n",
    "# Load models\n",
    "print(\"\\nðŸ“Š Loading models...\")\n",
    "models = {}\n",
    "props = ['minutes', 'points', 'rebounds', 'assists', 'threes']\n",
    "\n",
    "for prop in props:\n",
    "    model_path = Path(f'models/{prop}_model.pkl')\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[prop] = pickle.load(f)\n",
    "        print(f\"   âœ… {prop.capitalize()}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(models)} models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Œ TODO: Add live prediction logic\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. For each game, get probable starters\")\n",
    "print(\"2. Fetch recent game logs (last 10 games)\")\n",
    "print(\"3. Use train_auto.py feature engineering\")\n",
    "print(\"4. Generate predictions\")\n",
    "print(\"5. Fetch betting lines\")\n",
    "print(\"6. Find value bets (model vs line difference > threshold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”§ Helper Functions (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE ENGINEERING - Reuse training code\n",
    "# ============================================================\n",
    "\n",
    "# Import feature engineering from train_auto.py\n",
    "# This ensures features match training exactly!\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/meep')\n",
    "\n",
    "try:\n",
    "    from train_auto import build_players_from_playerstats\n",
    "    print(\"âœ… Imported feature engineering from train_auto.py\")\n",
    "    print(\"   This ensures features match training schema exactly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import: {e}\")\n",
    "    print(\"   Make sure you ran the Setup cell first\")\n",
    "\n",
    "# TODO: Add helper functions for:\n",
    "# - Fetching player recent games\n",
    "# - Converting API data to training schema\n",
    "# - Generating predictions\n",
    "# - Comparing to betting lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Evaluation & Performance Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATION - Track accuracy and ROI\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, prop_name):\n",
    "    \"\"\"\n",
    "    Calculate prediction accuracy metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Actual values\n",
    "        y_pred: Predicted values\n",
    "        prop_name: Property being predicted (points, rebounds, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dict of metrics\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Directional accuracy (for betting)\n",
    "    # TODO: Compare to betting lines\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {prop_name.upper()} Performance:\")\n",
    "    print(f\"   RMSE: {rmse:.3f}\")\n",
    "    print(f\"   MAE: {mae:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'prop': prop_name\n",
    "    }\n",
    "\n",
    "# TODO: Add betting performance tracking\n",
    "# - Win rate (over/under)\n",
    "# - ROI calculation\n",
    "# - Kelly criterion sizing\n",
    "# - Bankroll tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ’° Betting Analysis (Value Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BETTING ANALYSIS - Find value bets\n",
    "# ============================================================\n",
    "\n",
    "def find_value_bets(predictions, lines, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Find value bets where model disagrees with betting line.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Dict of player predictions {player_name: {prop: prediction}}\n",
    "        lines: Dict of betting lines {player_name: {prop: line}}\n",
    "        threshold: Minimum difference to consider (default: 2.0)\n",
    "    \n",
    "    Returns:\n",
    "        List of value bets sorted by edge\n",
    "    \"\"\"\n",
    "    value_bets = []\n",
    "    \n",
    "    for player, preds in predictions.items():\n",
    "        if player not in lines:\n",
    "            continue\n",
    "        \n",
    "        player_lines = lines[player]\n",
    "        \n",
    "        for prop, pred_value in preds.items():\n",
    "            if prop not in player_lines:\n",
    "                continue\n",
    "            \n",
    "            line = player_lines[prop]\n",
    "            edge = abs(pred_value - line)\n",
    "            \n",
    "            if edge >= threshold:\n",
    "                direction = 'OVER' if pred_value > line else 'UNDER'\n",
    "                \n",
    "                value_bets.append({\n",
    "                    'player': player,\n",
    "                    'prop': prop,\n",
    "                    'prediction': pred_value,\n",
    "                    'line': line,\n",
    "                    'edge': edge,\n",
    "                    'direction': direction,\n",
    "                    'confidence': edge / threshold  # Simple confidence metric\n",
    "                })\n",
    "    \n",
    "    # Sort by edge (highest first)\n",
    "    value_bets.sort(key=lambda x: x['edge'], reverse=True)\n",
    "    \n",
    "    return value_bets\n",
    "\n",
    "# TODO: Add Kelly criterion bet sizing\n",
    "# TODO: Add odds fetching (API integration)\n",
    "# TODO: Add historical bet tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ Notes & Documentation\n",
    "\n",
    "### Model Details:\n",
    "- **Architecture:** Neural Hybrid (TabNet + LightGBM)\n",
    "- **Features:** ~218 raw features + 24 TabNet embeddings = 242 total\n",
    "- **Training Data:** 1.6M+ player-games (1974-2025)\n",
    "- **Expected Accuracy:** Points MAE ~3.0 (Â±3 points)\n",
    "\n",
    "### Feature Engineering:\n",
    "- Phase 1-7: All phases from training\n",
    "- Basketball Reference priors: ~68 advanced stats\n",
    "- Momentum features: Short/medium/long-term trends\n",
    "- Situational context: Rest, schedule density, opponent history\n",
    "\n",
    "### Betting Strategy:\n",
    "- Find value when |prediction - line| > threshold (default: 2.0)\n",
    "- Need 52.4% accuracy to beat -110 vig\n",
    "- Target: 60-65% accuracy on value bets\n",
    "- Expected ROI: +15-25%\n",
    "\n",
    "### TODO:\n",
    "1. Implement backtest logic\n",
    "2. Implement live prediction pipeline\n",
    "3. Add betting line fetching (API)\n",
    "4. Add performance tracking\n",
    "5. Add Kelly criterion bet sizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}