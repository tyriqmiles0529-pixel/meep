{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Meta-Learner Training (Kaggle)\n",
    "\n",
    "Train context-aware meta-learner using 27 window models.\n",
    "\n",
    "**Requirements:**\n",
    "- GPU: T4 or P100 (free on Kaggle)\n",
    "- Dataset: Historical NBA Data and Player Box Scores (Kaggle)\n",
    "- Window models: Upload to Kaggle dataset or download from Modal\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Load 27 window models from Kaggle dataset\n",
    "3. Load PlayerStatistics.csv (2024-2025 season)\n",
    "4. Collect window predictions for each prop\n",
    "5. Train meta-learner with OOF cross-validation\n",
    "6. Download meta_learner_2025_2026.pkl\n",
    "7. Upload to Modal: `modal volume put nba-models meta_learner_2025_2026.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-tabnet lightgbm scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Project Files\n",
    "\n",
    "**Option A**: Upload as Kaggle dataset\n",
    "- Create dataset with: ensemble_predictor.py, meta_learner_ensemble.py, hybrid_multi_task.py, etc.\n",
    "- Add as dataset dependency\n",
    "\n",
    "**Option B**: Copy-paste code into cells (simpler for first run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Copy code from GitHub\n",
    "# You'll need to paste ensemble_predictor.py and meta_learner_ensemble.py code here\n",
    "# OR upload them as a Kaggle dataset\n",
    "\n",
    "# For now, we'll assume they're in /kaggle/input/nba-predictor-code/\n",
    "sys.path.insert(0, '/kaggle/input/nba-predictor-code/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Window Models\n",
    "\n",
    "**Upload window models to Kaggle dataset:**\n",
    "1. Download from Modal: `modal volume get nba-models model_cache/`\n",
    "2. Create Kaggle dataset \"nba-window-models\" with all .pkl files\n",
    "3. Add as dataset dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_predictor import load_all_window_models\n",
    "\n",
    "# Path to window models (uploaded as Kaggle dataset)\n",
    "model_cache_dir = \"/kaggle/input/nba-window-models/\"\n",
    "\n",
    "print(\"Loading 27 window models...\")\n",
    "window_models = load_all_window_models(model_cache_dir)\n",
    "print(f\"✓ Loaded {len(window_models)} windows\")\n",
    "\n",
    "for window_name in list(window_models.keys())[:5]:\n",
    "    print(f\"  - {window_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Training Data (2024-2025 Season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PlayerStatistics.csv from Kaggle dataset\n",
    "csv_path = \"/kaggle/input/historical-nba-data-and-player-box-scores/PlayerStatistics.csv\"\n",
    "\n",
    "print(f\"Loading {csv_path}...\")\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "\n",
    "# Parse gameDate and extract season\n",
    "df['gameDate'] = pd.to_datetime(df['gameDate'], format='mixed', utc=True)\n",
    "df['gameDate'] = df['gameDate'].dt.tz_localize(None)\n",
    "df['year'] = df['gameDate'].dt.year\n",
    "df['month'] = df['gameDate'].dt.month\n",
    "\n",
    "# NBA season: Oct-June (games from Oct-Dec are start of season)\n",
    "df['season_year'] = df.apply(\n",
    "    lambda row: row['year'] if row['month'] >= 10 else row['year'] - 1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to 2024-2025 season\n",
    "training_season = \"2024-2025\"\n",
    "season_start_year = 2024\n",
    "df = df[df['season_year'] == season_start_year]\n",
    "\n",
    "print(f\"Filtered to {training_season}: {len(df):,} records\")\n",
    "print(f\"Date range: {df['gameDate'].min()} to {df['gameDate'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Collect Window Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_predictor import predict_with_window\n",
    "\n",
    "def collect_predictions(prop_name: str, sample_size: int = 5000):\n",
    "    \"\"\"Collect window predictions and actuals for a prop\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"COLLECTING PREDICTIONS: {prop_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Column mapping\n",
    "    prop_col_map = {\n",
    "        'points': 'points',\n",
    "        'rebounds': 'reboundsTotal',\n",
    "        'assists': 'assists',\n",
    "        'threes': 'threePointersMade'\n",
    "    }\n",
    "    \n",
    "    if prop_name not in prop_col_map:\n",
    "        print(f\"[!] Unknown prop: {prop_name}\")\n",
    "        return None\n",
    "    \n",
    "    actual_col = prop_col_map[prop_name]\n",
    "    \n",
    "    window_preds = []\n",
    "    contexts = []\n",
    "    actuals = []\n",
    "    \n",
    "    # Sample games\n",
    "    sample_df = df.sample(min(sample_size, len(df)), random_state=42)\n",
    "    \n",
    "    for idx, (_, game) in enumerate(sample_df.iterrows(), 1):\n",
    "        actual = game.get(actual_col)\n",
    "        if pd.isna(actual) or actual < 0:\n",
    "            continue\n",
    "        \n",
    "        # Get predictions from each window\n",
    "        preds = []\n",
    "        for window_name, models in window_models.items():\n",
    "            try:\n",
    "                # Create feature row\n",
    "                X = pd.DataFrame([{\n",
    "                    'fieldGoalsAttempted': game.get('fieldGoalsAttempted', 0),\n",
    "                    'freeThrowsAttempted': game.get('freeThrowsAttempted', 0),\n",
    "                    'assists': game.get('assists', 0),\n",
    "                    'rebounds': game.get('reboundsTotal', 0),\n",
    "                    'threes': game.get('threePointersMade', 0),\n",
    "                    'points': game.get('points', 0),\n",
    "                    'numMinutes': game.get('numMinutes', 0),\n",
    "                }])\n",
    "                \n",
    "                pred = predict_with_window(models, X, prop_name)\n",
    "                if isinstance(pred, np.ndarray):\n",
    "                    pred = pred[0] if len(pred) > 0 else 0.0\n",
    "                preds.append(pred if pred is not None else 0.0)\n",
    "            except Exception as e:\n",
    "                if idx == 1:\n",
    "                    print(f\"  [!] Window {window_name} failed: {e}\")\n",
    "                preds.append(0.0)\n",
    "        \n",
    "        if len(preds) < 20:\n",
    "            continue\n",
    "        \n",
    "        # Pad to 27\n",
    "        while len(preds) < 27:\n",
    "            preds.append(np.mean(preds))\n",
    "        \n",
    "        window_preds.append(preds[:27])\n",
    "        \n",
    "        # Extract context\n",
    "        contexts.append({\n",
    "            'position_encoded': 2,\n",
    "            'usage_rate': 0.20,\n",
    "            'minutes_avg': game.get('numMinutes', 30),\n",
    "            'is_home': int(game.get('home', 0)),\n",
    "        })\n",
    "        \n",
    "        actuals.append(actual)\n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            non_zero = sum(1 for p in preds if p != 0.0)\n",
    "            print(f\"  Processed {idx}/{len(sample_df)} games... (non-zero preds: {non_zero}/27)\")\n",
    "    \n",
    "    print(f\"  ✓ Collected {len(actuals):,} samples\")\n",
    "    \n",
    "    if len(actuals) < 100:\n",
    "        print(f\"  [!] Not enough samples\")\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'window_predictions': np.array(window_preds),\n",
    "        'player_context': pd.DataFrame(contexts),\n",
    "        'actuals': np.array(actuals)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_learner_ensemble import ContextAwareMetaLearner\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING META-LEARNER\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "meta_learner = ContextAwareMetaLearner(n_windows=27, cv_folds=5)\n",
    "\n",
    "results = {}\n",
    "for prop in ['points', 'rebounds', 'assists', 'threes']:\n",
    "    data = collect_predictions(prop, sample_size=5000)\n",
    "    \n",
    "    if data is None:\n",
    "        results[prop] = \"skipped\"\n",
    "        continue\n",
    "    \n",
    "    # Train with OOF\n",
    "    metrics = meta_learner.fit_oof(\n",
    "        window_predictions=data['window_predictions'],\n",
    "        y_true=data['actuals'],\n",
    "        player_context=data['player_context'],\n",
    "        prop_name=prop\n",
    "    )\n",
    "    \n",
    "    results[prop] = {\n",
    "        'samples': len(data['actuals']),\n",
    "        'improvement_rmse': f\"{metrics['improvement_rmse_pct']:+.1f}%\",\n",
    "        'oof_rmse': f\"{metrics['oof_rmse']:.3f}\",\n",
    "        'baseline_rmse': f\"{metrics['baseline_rmse']:.3f}\"\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Props trained: {len(meta_learner.meta_models)}\")\n",
    "print(f\"\\nResults:\")\n",
    "for prop, result in results.items():\n",
    "    if isinstance(result, dict):\n",
    "        print(f\"  {prop:12s}: {result['samples']:5,} samples, {result['improvement_rmse']} improvement\")\n",
    "    else:\n",
    "        print(f\"  {prop:12s}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"meta_learner_2025_2026.pkl\"\n",
    "\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(meta_learner, f)\n",
    "\n",
    "print(f\"\\n✅ Saved: {output_file}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Download {output_file} from Kaggle (Output section)\")\n",
    "print(f\"2. Upload to Modal: modal volume put nba-models {output_file}\")\n",
    "print(f\"3. Run analyzer: modal run modal_analyzer.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which windows are most important\n",
    "for prop_name, model in meta_learner.meta_models.items():\n",
    "    print(f\"\\n{prop_name.upper()} - Top 10 Features:\")\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    feature_names = meta_learner.get_feature_names(n_windows=27)\n",
    "    \n",
    "    feature_importance = sorted(\n",
    "        zip(feature_names, importances),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for feat, imp in feature_importance[:10]:\n",
    "        print(f\"  {feat:30s}: {imp:7.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
