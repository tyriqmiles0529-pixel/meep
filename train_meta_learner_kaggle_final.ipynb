{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Meta-Learner Training (Kaggle - FINAL)\n",
    "\n",
    "**Requirements:**\n",
    "- GPU: T4 or P100 (Settings → Accelerator → GPU T4 x2)\n",
    "- Internet: ON (Settings → Internet → ON)\n",
    "- Datasets (Click 'Add Data'):\n",
    "  1. **nba-window-models** (your dataset with 27 .pkl files)\n",
    "  2. **nba-predictor-code** (your dataset with kaggle_code.tar.gz)\n",
    "  3. **historical-nba-data-and-player-box-scores** (Eoin Moore)\n",
    "\n",
    "**Output:**\n",
    "- `meta_learner_2025_2026.pkl` - Download from Output tab\n",
    "- Upload to Modal: `modal volume put nba-models meta_learner_2025_2026.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup - Add Code Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Add code path BEFORE any imports\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/input/nba-predictor-code')\n",
    "\n",
    "print(\"✓ Code path added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-tabnet lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Window Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"/kaggle/input/nba-window-models\")\n",
    "model_files = sorted(model_dir.glob(\"player_models_*.pkl\"))\n",
    "\n",
    "print(f\"Found {len(model_files)} window models\")\n",
    "\n",
    "# Load all models\n",
    "window_models = []\n",
    "for model_file in model_files:\n",
    "    print(f\"Loading {model_file.name}...\", end=\" \")\n",
    "    with open(model_file, 'rb') as f:\n",
    "        models = pickle.load(f)\n",
    "    window_models.append(models)\n",
    "    print(\"✓\")\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(window_models)} windows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Training Data (2024-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/kaggle/input/historical-nba-data-and-player-box-scores/PlayerStatistics.csv\"\n",
    "\n",
    "print(f\"Loading {csv_path}...\")\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "\n",
    "# Parse dates and extract season\n",
    "df['gameDate'] = pd.to_datetime(df['gameDate'], format='mixed', utc=True, errors='coerce')\n",
    "df['gameDate'] = df['gameDate'].dt.tz_localize(None)\n",
    "df['year'] = df['gameDate'].dt.year\n",
    "df['month'] = df['gameDate'].dt.month\n",
    "\n",
    "# NBA season: Oct-June\n",
    "df['season_year'] = df.apply(\n",
    "    lambda row: row['year'] if row['month'] >= 10 else row['year'] - 1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to 2024-2025\n",
    "df_train = df[df['season_year'] == 2024].copy()\n",
    "print(f\"2024-2025 season: {len(df_train):,} records\")\n",
    "\n",
    "# Sample for training (2000 games max for speed)\n",
    "df_train = df_train.sample(min(2000, len(df_train)), random_state=42)\n",
    "print(f\"Training sample: {len(df_train):,} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Collect Window Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_from_window(window_model, game_row, prop_name):\n",
    "    try:\n",
    "        features = pd.DataFrame([{\n",
    "            'points': float(game_row.get('points', 0)),\n",
    "            'assists': float(game_row.get('assists', 0)),\n",
    "            'reboundsTotal': float(game_row.get('reboundsTotal', 0)),\n",
    "            'threePointersMade': float(game_row.get('threePointersMade', 0)),\n",
    "            'numMinutes': float(game_row.get('numMinutes', 0)),\n",
    "            'fieldGoalsAttempted': float(game_row.get('fieldGoalsAttempted', 0)),\n",
    "            'freeThrowsAttempted': float(game_row.get('freeThrowsAttempted', 0)),\n",
    "        }])\n",
    "        if isinstance(window_model, dict) and 'multi_task_model' in window_model:\n",
    "            model = window_model['multi_task_model']\n",
    "            if hasattr(model, 'predict'):\n",
    "                preds = model.predict(features)\n",
    "                if isinstance(preds, dict) and prop_name in preds:\n",
    "                    return float(preds[prop_name][0])\n",
    "        if isinstance(window_model, dict) and prop_name in window_model:\n",
    "            model = window_model[prop_name]\n",
    "            if model is not None and hasattr(model, 'predict'):\n",
    "                pred = model.predict(features)\n",
    "                return float(pred[0])\n",
    "        return 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def collect_predictions_simple(prop_name, actual_col_name):\n",
    "    print(f\"\\nCOLLECTING: {prop_name.upper()}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Test first window\n",
    "    test_game = df_train.iloc[0]\n",
    "    test_pred = get_prediction_from_window(window_models[0], test_game, prop_name)\n",
    "    print(f\"Test prediction from first window: {test_pred}\")\n",
    "    \n",
    "    window_preds = []\n",
    "    actuals = []\n",
    "    contexts = []\n",
    "    \n",
    "    total = len(df_train)\n",
    "    print(f\"Processing {total} games...\")\n",
    "    \n",
    "    for idx in range(total):\n",
    "        if idx % 200 == 0:\n",
    "            print(f\"  Progress: {idx}/{total}\")\n",
    "        \n",
    "        game = df_train.iloc[idx]\n",
    "        actual = game.get(actual_col_name)\n",
    "        if pd.isna(actual) or actual < 0:\n",
    "            continue\n",
    "        \n",
    "        preds = []\n",
    "        for window in window_models:\n",
    "            preds.append(get_prediction_from_window(window, game, prop_name))\n",
    "        \n",
    "        non_zero = sum(1 for p in preds if p != 0.0)\n",
    "        if non_zero < 10:\n",
    "            continue\n",
    "        \n",
    "        while len(preds) < 27:\n",
    "            preds.append(np.mean([p for p in preds if p != 0.0]))\n",
    "        \n",
    "        window_preds.append(preds[:27])\n",
    "        actuals.append(actual)\n",
    "        \n",
    "        contexts.append({\n",
    "            'minutes': game.get('numMinutes', 30),\n",
    "            'is_home': int(game.get('home', 0)),\n",
    "        })\n",
    "    \n",
    "    print(f\"✓ Collected {len(actuals)} samples\")\n",
    "    print(f\"  Sample predictions: {window_preds[0][:5] if len(window_preds) > 0 else 'none'}\")\n",
    "    \n",
    "    return {\n",
    "        'window_preds': np.array(window_preds),\n",
    "        'actuals': np.array(actuals),\n",
    "        'context': pd.DataFrame(contexts)\n",
    "    }\n",
    "\n",
    "# Collect all props\n",
    "prop_data = {}\n",
    "props = {\n",
    "    'points': 'points',\n",
    "    'rebounds': 'reboundsTotal',\n",
    "    'assists': 'assists',\n",
    "    'threes': 'threePointersMade'\n",
    "}\n",
    "\n",
    "for prop_name, col_name in props.items():\n",
    "    prop_data[prop_name] = collect_predictions_simple(prop_name, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_model(prop_name, data):\n",
    "    print(f\"\\nTraining meta-learner: {prop_name.upper()}\")\n",
    "    \n",
    "    X = data['window_preds']\n",
    "    y = data['actuals']\n",
    "    context = data['context']\n",
    "    \n",
    "    # Combine window predictions + context\n",
    "    X_full = np.hstack([X, context.values])\n",
    "    \n",
    "    # Baseline: simple average\n",
    "    baseline_preds = np.mean(X, axis=1)\n",
    "    baseline_rmse = np.sqrt(mean_squared_error(y, baseline_preds))\n",
    "    \n",
    "    # Train with 5-fold OOF\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    oof_preds = np.zeros(len(y))\n",
    "    \n",
    "    models = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_full), 1):\n",
    "        X_train, X_val = X_full[train_idx], X_full[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            num_leaves=31,\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "        models.append(model)\n",
    "    \n",
    "    oof_rmse = np.sqrt(mean_squared_error(y, oof_preds))\n",
    "    improvement = ((baseline_rmse - oof_rmse) / baseline_rmse) * 100\n",
    "    \n",
    "    print(f\"  Baseline RMSE: {baseline_rmse:.3f}\")\n",
    "    print(f\"  OOF RMSE:      {oof_rmse:.3f}\")\n",
    "    print(f\"  Improvement:   {improvement:+.1f}%\")\n",
    "    \n",
    "    # Train final model on all data\n",
    "    final_model = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    final_model.fit(X_full, y)\n",
    "    \n",
    "    return {\n",
    "        'model': final_model,\n",
    "        'baseline_rmse': baseline_rmse,\n",
    "        'oof_rmse': oof_rmse,\n",
    "        'improvement_pct': improvement\n",
    "    }\n",
    "\n",
    "# Train all props\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING META-LEARNER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "meta_models = {}\n",
    "results = {}\n",
    "\n",
    "for prop_name, data in prop_data.items():\n",
    "    if len(data['actuals']) < 100:\n",
    "        print(f\"\\nSkipping {prop_name}: not enough samples\")\n",
    "        continue\n",
    "    \n",
    "    result = train_meta_model(prop_name, data)\n",
    "    meta_models[prop_name] = result['model']\n",
    "    results[prop_name] = result\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "for prop, res in results.items():\n",
    "    print(f\"{prop:12s}: {res['improvement_pct']:+.1f}% improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-learner object\n",
    "meta_learner = {\n",
    "    'meta_models': meta_models,\n",
    "    'n_windows': 27,\n",
    "    'results': results,\n",
    "    'training_season': '2024-2025',\n",
    "    'training_samples': {prop: len(data['actuals']) for prop, data in prop_data.items()}\n",
    "}\n",
    "\n",
    "# Save\n",
    "output_file = \"meta_learner_2025_2026.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(meta_learner, f)\n",
    "\n",
    "print(f\"✅ Saved: {output_file}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Download {output_file} from Output tab\")\n",
    "print(f\"2. Upload to Modal: modal volume put nba-models {output_file}\")\n",
    "print(f\"3. Run analyzer: modal run modal_analyzer.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
